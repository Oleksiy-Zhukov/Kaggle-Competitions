{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zhukovoleksiy/ps-s3e18-eda-ensembles-tabpfn?scriptVersionId=143915387\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# <h2 style = \"font-family:Georgia;font-weight: bold; font-size:30px; background-color: white; color : #1192AA; border-radius: 100px 100px; text-align:left\">Table of Contents</h2>\n\n* &nbsp; **[Introduction](#Introduction)**\n\n    * &nbsp; **[Getting Started](#Getting-Started)** \n    \n    * &nbsp; **[Metadata](#Metadata)** \n    \n    * &nbsp; **[Objective](#Objective)** \n    \n* &nbsp; **[Import](#Import)**\n\n* &nbsp; **[Check Dataset](#Check-Dataset)**\n   \n* &nbsp; **[Exploratory Data Analysis](#EDA)**\n    \n* &nbsp; **[Feature Engineering](#Feature-Engineering)**\n    \n* &nbsp; **[Model Building](#Model-Building)**\n\n    * &nbsp; **[First Method: Optuna Ensembels](#First-Method:-Optuna-Ensembels)** \n    \n    * &nbsp; **[Second Method: TabPFN](#Second-Method:-TabPFN)** \n\n* &nbsp; **[Submission](#Submission)**","metadata":{}},{"cell_type":"markdown","source":"<h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Introduction</h1>","metadata":{}},{"cell_type":"markdown","source":"<img src = 'https://www.thoughtco.com/thmb/ZAyr-1lDbfchbzgVaaOJicjzHQ0=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/what-is-enzyme-structure-and-function-375555_v4-6f22f82931824e76b1c31401230deac8.png'>","metadata":{}},{"cell_type":"markdown","source":"## Getting Started","metadata":{}},{"cell_type":"markdown","source":"* Welcome to my Kaggle Notebook for the latest Kaggle Playground Series, [\"Explore Multi-Label Classification with an Enzyme Substrate Dataset.\"](https://www.kaggle.com/competitions/playground-series-s3e18) In this competition, our goal is to predict the probability of two targets, EC1 and EC2, for the test dataset.\n\n* The [dataset](https://www.kaggle.com/competitions/playground-series-s3e18/data) provided for this challenge contains a collection of molecular data, specifically related to enzyme classes. Each entry represents a unique molecule, and the dataset includes various features that capture important molecular properties and characteristics. Some of these features include the Bertz complexity index, molecular connectivity indices, electrotopological states, molecular weights, and other molecular descriptors.\n\n* [Enzymes](https://en.wikipedia.org/wiki/Enzyme) are known to act on molecules with structural similarities with their substrates. This behaviour is called promiscuity. Scientists working in drug discovery use this behaviour to target/design drugs to either block or promote biological actions. But, correct prediction of EC class(s) of substrates associated with enzymes has been a challenge in biology. Since there is no shortage of data, ML techniques can be employed to solve the aforementioned problem.","metadata":{}},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"markdown","source":"(from https://www.kaggle.com/code/tumpanjawat/s3e18-eda-cluster-ensemble-ada-cat-gb#INTRODUCTION)\n\n1. Id: This feature represents the identifier or unique identification number of a molecule. It serves as a reference but doesn't directly contribute to the predictive model.\n\n2. BertzCT: This feature corresponds to the Bertz complexity index, which measures the structural complexity of a molecule. It can provide insights into the intricacy of molecular structures.\n\n3. Chi1: The Chi1 feature denotes the 1st order molecular connectivity index, which describes the topological connectivity of atoms in a molecule. It characterizes the atomic bonding pattern within the molecule.\n\n4. Chi1n: This feature is the normalized version of the Chi1 index. It allows for standardized comparisons of the 1st order molecular connectivity across different molecules.\n\n5. Chi1v: The Chi1v feature represents the 1st order molecular variance connectivity index. It captures the variance or diversity in the connectivity of atoms within a molecule.\n\n6. Chi2n: The Chi2n feature indicates the 2nd order molecular connectivity index, which provides information about the extended connectivity of atoms in a molecule. It considers the neighboring atoms of each atom in the molecule.\n\n7. Chi2v: Similar to Chi2n, the Chi2v feature measures the variance or diversity in the extended connectivity of atoms within a molecule at the 2nd order level.\n\n8. Chi3v: The Chi3v feature represents the 3rd order molecular variance connectivity index. It captures the variance in the 3rd order connectivity patterns among atoms in a molecule.\n\n9. Chi4n: This feature corresponds to the 4th order molecular connectivity index, which provides information about the extended connectivity of atoms in a molecule. The Chi4n index is normalized to allow for consistent comparisons across molecules.\n\n10. EState_VSA1: EState_VSA1 is a feature that relates to the electrotopological state of a molecule. Specifically, it represents the Van der Waals surface area contribution for a specific atom type, contributing to the overall electrotopological state.\n\n11. EState_VSA2: Similar to EState_VSA1, EState_VSA2 also represents the electrotopological state but for a different specific atom type.\n\n12. ExactMolWt: This feature denotes the exact molecular weight of a molecule. It provides an accurate measurement of the mass of the molecule.\n\n13. FpDensityMorgan1: FpDensityMorgan1 represents the Morgan fingerprint density for a specific radius of 1. Morgan fingerprints are a method for generating molecular fingerprints, and this feature captures the density of those fingerprints.\n\n14. FpDensityMorgan2: Similar to FpDensityMorgan1, this feature represents the Morgan fingerprint density for a specific radius of 2.\n\n15. FpDensityMorgan3: FpDensityMorgan3 corresponds to the Morgan fingerprint density for a specific radius of 3.\n\n16. HallkierAlpha: The HallkierAlpha feature denotes the Hall-Kier alpha value for a molecule. It is a measure of molecular shape and can provide insights into the overall structure of the molecule.\n\n17. HeavyAtomMolWt: This feature represents the molecular weight of heavy atoms only, excluding hydrogen atoms. It focuses on the mass of non-hydrogen atoms within the molecule.\n\n18. Kappa3: The Kappa3 feature corresponds to the Hall-Kier Kappa3 value, which is a molecular shape descriptor. It provides information about the shape and spatial arrangement of atoms within the molecule.\n\n19. MaxAbsEStateIndex: This feature represents the maximum absolute value of the E-state index. The E-state index relates to the electronic properties of a molecule, and its maximum absolute value can indicate the presence of specific electronic characteristics.\n\n20. MinEStateIndex: MinEStateIndex denotes the minimum value of the E-state index. It provides information about the lowest observed electronic property value within the molecule.\n\n21. NumHeteroatoms: This feature indicates the number of heteroatoms present in a molecule. Heteroatoms are atoms other than carbon and hydrogen, such as oxygen, nitrogen, sulfur, etc. This feature provides insights into the diversity and composition of atoms within the molecule.\n\n22. PEOE_VSA10: PEOE_VSA10 represents the partial equalization of orbital electronegativity Van der Waals surface area contribution for a specific atom type. It captures the surface area contribution of a particular atom type to the overall electrostatic properties.\n\n23. PEOE_VSA14: Similar to PEOE_VSA10, PEOE_VSA14 also represents the partial equalization of orbital electronegativity Van der Waals surface area contribution for a specific atom type.\n\n24. PEOE_VSA6: This feature corresponds to the partial equalization of orbital electronegativity Van der Waals surface area contribution for a specific atom type at a different level.\n\n25. PEOE_VSA7: Similar to PEOE_VSA6, PEOE_VSA7 represents the partial equalization of orbital electronegativity Van der Waals surface area contribution for a specific atom type.\n\n26. PEOE_VSA8: PEOE_VSA8 denotes the partial equalization of orbital electronegativity Van der Waals surface area contribution for a specific atom type.\n\n27. SMR_VSA10: SMR_VSA10 represents the solvent-accessible surface area Van der Waals surface area contribution for a specific atom type. It captures the contribution of a specific atom type to the solvent-accessible surface area.\n\n28. SMR_VSA5: Similar to SMR_VSA10, this feature denotes the solvent-accessible surface area Van der Waals surface area contribution for a specific atom type at a different level.\n\n29. SlogP_VSA3: The SlogP_VSA3 feature represents the LogP-based surface area contribution. It captures the contribution of a specific atom type to the surface area based on its logarithmic partition coefficient.\n\n30. VSA_EState9: This feature denotes the E-state fragment contribution for the Van der Waals surface area calculation. It captures the fragment-specific contribution to the electrostatic properties of the molecule.\n\n31. fr_COO: The fr_COO feature represents the number of carboxyl (COO) functional groups present in the molecule. It ranges from 0 to 8, providing insights into the presence and abundance of carboxyl groups.\n\n32. fr_COO2: Similar to fr_COO, fr_COO2 represents the number of carboxyl (COO) functional groups, ranging from 0 to 8.\n\n33. EC1: EC1 is a binary feature representing a predicted label related to Oxidoreductases. It serves as one of the target variables for prediction.\n\n32. EC2: EC2 is another binary feature representing a predicted label related to Transferases. It serves as another target variable for prediction.","metadata":{}},{"cell_type":"markdown","source":"## Objective","metadata":{}},{"cell_type":"markdown","source":"* In this notebook, I will present two different approaches to tackle this multi-label classification problem. The first approach involves using two ensembles of models, such as XGBoost, LGBM, and CatBoost, to predict each target feature (EC1 and EC2) separately. This ensemble approach will allow us to leverage the strengths of each model and improve the overall predictive performance.\n\n* The second approach is an experimental one, where I will explore the use of [TabPFN](https://github.com/automl/TabPFN) (Tabular Pretrained Fusion Networks). TabPFN is a cutting-edge technique that combines pretraining on large-scale tabular data with fine-tuning on the target task. By leveraging the power of transfer learning, TabPFN has shown promising results in various tabular data classification problems. We will experiment with TabPFN to see if it can effectively predict the enzyme classes in this dataset.","metadata":{}},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Import</h1>","metadata":{}},{"cell_type":"code","source":"# Misc\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nfrom copy import deepcopy\nfrom functools import partial\nfrom itertools import combinations\nimport random\nimport gc\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport seaborn as sns\nfrom category_encoders import OrdinalEncoder, CountEncoder, CatBoostEncoder, OneHotEncoder\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder # OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\nfrom sklearn.decomposition import PCA, NMF\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.compose import make_column_selector\n\n# Import libraries for Hypertuning\nimport optuna\n\n# Import libraries for gradient boosting\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost.callback import EarlyStopping\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool\n\n# Useful line of code to set the display option so we could see all the columns in pd dataframe\npd.set_option('display.max_columns', None)\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-01T19:54:00.411116Z","iopub.execute_input":"2023-07-01T19:54:00.411585Z","iopub.status.idle":"2023-07-01T19:54:00.42497Z","shell.execute_reply.started":"2023-07-01T19:54:00.411555Z","shell.execute_reply":"2023-07-01T19:54:00.423944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Check Dataset</h1>","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/playground-series-s3e18/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/playground-series-s3e18/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/playground-series-s3e18/sample_submission.csv\")\noriginal_desc = pd.read_csv(\"/kaggle/input/ec-mixed-class/mixed_desc.csv\")\n\ntarget_col = ['EC1', 'EC2']\n\ncolumns_to_keep = ['CIDs', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n                   'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n                   'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n                   'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n                   'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n                   'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n                   'fr_COO', 'fr_COO2', 'EC1_EC2_EC3_EC4_EC5_EC6']\n\noriginal = original_desc.loc[:, columns_to_keep]\n\n# There is probably a better way to do this, but that is was first came to my mind\nfeature1 = []\nfeature2 = []\nfor x in original['EC1_EC2_EC3_EC4_EC5_EC6']:\n    feature1.append(int(x.split('_')[0]))\n    feature2.append(int(x.split('_')[1]))\n\noriginal['EC1'] = feature1\noriginal['EC2'] = feature2\n\noriginal.drop(columns = ['EC1_EC2_EC3_EC4_EC5_EC6', 'CIDs'], inplace=True)\noriginal['id'] = original.reset_index().index\n\ndf_train.drop(columns = ['EC3', 'EC4', 'EC5', 'EC6'], inplace=True)\n\n\nnumerical_columns = ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n                   'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n                   'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n                   'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n                   'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n                   'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9']\n\ncat_cols = ['fr_COO', 'fr_COO2']\n\nprint(f'Data Successfully Loaded \\n')\n\nprint(f'[INFO] Shapes:'\n      f'\\n original: {original.shape}'\n      f'\\n train: {df_train.shape}'\n      f'\\n test: {df_test.shape}\\n')\n\nprint(f'[INFO] Any missing values:'\n      f'\\n original: {original.isna().any().any()}'\n      f'\\n train: {df_train.isna().any().any()}'\n      f'\\n test: {df_test.isna().any().any()}')","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:45:39.646028Z","iopub.execute_input":"2023-07-01T19:45:39.646566Z","iopub.status.idle":"2023-07-01T19:45:40.022614Z","shell.execute_reply.started":"2023-07-01T19:45:39.646524Z","shell.execute_reply":"2023-07-01T19:45:40.02138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:45:40.688481Z","iopub.execute_input":"2023-07-01T19:45:40.689411Z","iopub.status.idle":"2023-07-01T19:45:40.738456Z","shell.execute_reply.started":"2023-07-01T19:45:40.689374Z","shell.execute_reply":"2023-07-01T19:45:40.737382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:45:41.092595Z","iopub.execute_input":"2023-07-01T19:45:41.093272Z","iopub.status.idle":"2023-07-01T19:45:41.127144Z","shell.execute_reply.started":"2023-07-01T19:45:41.093237Z","shell.execute_reply":"2023-07-01T19:45:41.12626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop(index=3422, inplace=True) # df_train[df_train['FpDensityMorgan1'] == -666]","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:45:42.43661Z","iopub.execute_input":"2023-07-01T19:45:42.437639Z","iopub.status.idle":"2023-07-01T19:45:42.449916Z","shell.execute_reply.started":"2023-07-01T19:45:42.437596Z","shell.execute_reply":"2023-07-01T19:45:42.448827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">EDA</h1>","metadata":{}},{"cell_type":"code","source":"# Create palette\n\nmy_palette = sns.cubehelix_palette(n_colors = 7, start=.46, rot=-.45, dark = .2, hue=0.95)\nsns.palplot(my_palette)\nplt.gcf().set_size_inches(13,2)\n\nfor idx,values in enumerate(my_palette.as_hex()):\n    plt.text(idx-0.375,0, my_palette.as_hex()[idx],{'font': \"Courier New\", 'size':16, 'weight':'bold','color':'black'}, alpha =0.7)\nplt.gcf().set_facecolor('white')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:02.970812Z","iopub.execute_input":"2023-06-30T17:33:02.971118Z","iopub.status.idle":"2023-06-30T17:33:03.18453Z","shell.execute_reply.started":"2023-06-30T17:33:02.971092Z","shell.execute_reply":"2023-06-30T17:33:03.182855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure and set style with white background\nplt.figure(figsize = (14, 8))\nsns.set_style('white')\n\n# set colors\ncolors = my_palette\n\n# plot\nplt.barh(df_train['EC1'].value_counts().index,\n        df_train['EC1'].value_counts(),\n        color = colors[1:3])\n\n# set title\nplt.title('EC1 Distribution in df_train', fontsize = 14, fontweight = 'bold')\n\n# remove spines from plot\nsns.despine()\n\n# display all open figures\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:03.187146Z","iopub.execute_input":"2023-06-30T17:33:03.187704Z","iopub.status.idle":"2023-06-30T17:33:03.58131Z","shell.execute_reply.started":"2023-06-30T17:33:03.187654Z","shell.execute_reply":"2023-06-30T17:33:03.580546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure and set style with white background\nplt.figure(figsize = (14, 8))\nsns.set_style('white')\n\n# set colors\ncolors = my_palette\n\n# plot\nplt.barh(df_train['EC2'].value_counts().index,\n        df_train['EC2'].value_counts(),\n        color = colors[1:3])\n\n# set title\nplt.title('EC2 Distribution in df_train', fontsize = 14, fontweight = 'bold')\n\n# remove spines from plot\nsns.despine()\n\n# display all open figures\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:03.582675Z","iopub.execute_input":"2023-06-30T17:33:03.583222Z","iopub.status.idle":"2023-06-30T17:33:03.989291Z","shell.execute_reply.started":"2023-06-30T17:33:03.583193Z","shell.execute_reply":"2023-06-30T17:33:03.988479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure and set style with white background\nplt.figure(figsize = (14, 8))\nsns.set_style('white')\n\n# set colors\ncolors = my_palette\n\n# plot\nplt.barh(original[\"EC1\"].value_counts().index,\n        original[\"EC1\"].value_counts(),\n        color = colors[3:5])\n\n# set title\nplt.title('EC1 Distribution in original', fontsize = 14, fontweight = 'bold')\n\n# remove spines from plot\nsns.despine()\n\n# display all open figures\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:03.992849Z","iopub.execute_input":"2023-06-30T17:33:03.993357Z","iopub.status.idle":"2023-06-30T17:33:04.392386Z","shell.execute_reply.started":"2023-06-30T17:33:03.993325Z","shell.execute_reply":"2023-06-30T17:33:04.391655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure and set style with white background\nplt.figure(figsize = (14, 8))\nsns.set_style('white')\n\n# set colors\ncolors = my_palette\n\n# plot\nplt.barh(original[\"EC2\"].value_counts().index,\n        original[\"EC2\"].value_counts(),\n        color = colors[3:5])\n\n# set title\nplt.title('EC2 Distribution in original', fontsize = 14, fontweight = 'bold')\n\n# remove spines from plot\nsns.despine()\n\n# display all open figures\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:04.393684Z","iopub.execute_input":"2023-06-30T17:33:04.394163Z","iopub.status.idle":"2023-06-30T17:33:04.813795Z","shell.execute_reply.started":"2023-06-30T17:33:04.394135Z","shell.execute_reply":"2023-06-30T17:33:04.812719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subplots\nfig, axes = plt.subplots(len(numerical_columns), 2, figsize=(14, 120))\n\n# Plot the histograms and box plots\nfor i, column in enumerate(numerical_columns):\n    # Histogram\n    sns.histplot(df_train[column], bins=30, kde=True, ax=axes[i, 0], color = my_palette[2])\n    axes[i, 0].set_title(f'Distribution of {column} in df_train')\n    axes[i, 0].set_xlabel('Value')\n    axes[i, 0].set_ylabel('Frequency')\n\n    # Box plot\n    sns.boxplot(df_train[column], ax=axes[i, 1], color = my_palette[1])\n    axes[i, 1].set_title(f'Box plot of {column} in df_train')\n    axes[i, 1].set_xlabel(column)\n    axes[i, 1].set_ylabel('Value')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:04.815066Z","iopub.execute_input":"2023-06-30T17:33:04.815811Z","iopub.status.idle":"2023-06-30T17:33:29.211102Z","shell.execute_reply.started":"2023-06-30T17:33:04.815781Z","shell.execute_reply":"2023-06-30T17:33:29.209713Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subplots\nfig, axes = plt.subplots(len(numerical_columns), 2, figsize=(14, 120))\n\n# Plot the histograms and box plots\nfor i, column in enumerate(numerical_columns):\n    # Histogram\n    sns.histplot(df_train[column], bins=30, kde=True, ax=axes[i, 0], color = my_palette[4])\n    axes[i, 0].set_title(f'Distribution of {column} in original')\n    axes[i, 0].set_xlabel('Value')\n    axes[i, 0].set_ylabel('Frequency')\n\n    # Box plot\n    sns.boxplot(df_train[column], ax=axes[i, 1], color = my_palette[3])\n    axes[i, 1].set_title(f'Box plot of {column} in original')\n    axes[i, 1].set_xlabel(column)\n    axes[i, 1].set_ylabel('Value')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:29.2129Z","iopub.execute_input":"2023-06-30T17:33:29.213304Z","iopub.status.idle":"2023-06-30T17:33:53.550657Z","shell.execute_reply.started":"2023-06-30T17:33:29.213269Z","shell.execute_reply":"2023-06-30T17:33:53.549591Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Feature Engineering </h1>","metadata":{}},{"cell_type":"code","source":"def cat_encoder(X_train, X_test, cat_cols, encode='label'):\n    \n    if encode == 'label':\n        ## Label Encoder\n        encoder = OrdinalEncoder(cols=cat_cols)\n        train_encoder = encoder.fit_transform(X_train[cat_cols]).astype(int)\n        test_encoder = encoder.transform(X_test[cat_cols]).astype(int)\n        X_train[cat_cols] = train_encoder[cat_cols]\n        X_test[cat_cols] = test_encoder[cat_cols]\n        encoder_cols = cat_cols\n    \n    else:\n        ## OneHot Encoder\n        encoder = OneHotEncoder(handle_unknown='ignore')\n        train_encoder = encoder.fit_transform(X_train[cat_cols]).astype(int)\n        test_encoder = encoder.transform(X_test[cat_cols]).astype(int)\n        X_train = pd.concat([X_train, train_encoder], axis=1)\n        X_test = pd.concat([X_test, test_encoder], axis=1)\n        X_train.drop(cat_cols, axis=1, inplace=True)\n        X_test.drop(cat_cols, axis=1, inplace=True)\n        encoder_cols = list(train_encoder.columns)\n        \n    return X_train, X_test, encoder_cols","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:03.567527Z","iopub.execute_input":"2023-07-01T19:46:03.567939Z","iopub.status.idle":"2023-07-01T19:46:03.577399Z","shell.execute_reply.started":"2023-07-01T19:46:03.56791Z","shell.execute_reply":"2023-07-01T19:46:03.575879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features(df):\n    \n    new_features = {\n        'BertzCT_MaxAbsEStateIndex_Ratio': df['BertzCT'] / (df['MaxAbsEStateIndex'] + 1e-12),\n        'BertzCT_ExactMolWt_Product': df['BertzCT'] * df['ExactMolWt'],\n        'NumHeteroatoms_FpDensityMorgan1_Ratio': df['NumHeteroatoms'] / (df['FpDensityMorgan1'] + 1e-12),\n        'VSA_EState9_EState_VSA1_Ratio': df['VSA_EState9'] / (df['EState_VSA1'] + 1e-12),\n        'PEOE_VSA10_SMR_VSA5_Ratio': df['PEOE_VSA10'] / (df['SMR_VSA5'] + 1e-12),\n        'Chi1v_ExactMolWt_Product': df['Chi1v'] * df['ExactMolWt'],\n        'Chi2v_ExactMolWt_Product': df['Chi2v'] * df['ExactMolWt'],\n        'Chi3v_ExactMolWt_Product': df['Chi3v'] * df['ExactMolWt'],\n        'EState_VSA1_NumHeteroatoms_Product': df['EState_VSA1'] * df['NumHeteroatoms'],\n        'PEOE_VSA10_Chi1_Ratio': df['PEOE_VSA10'] / (df['Chi1'] + 1e-12),\n        'MaxAbsEStateIndex_NumHeteroatoms_Ratio': df['MaxAbsEStateIndex'] / (df['NumHeteroatoms'] + 1e-12),\n        'BertzCT_Chi1_Ratio': df['BertzCT'] / (df['Chi1'] + 1e-12),\n    }\n    \n    df = df.assign(**new_features)\n    new_cols = list(new_features.keys())\n    \n    return df, new_cols","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:03.97248Z","iopub.execute_input":"2023-07-01T19:46:03.973344Z","iopub.status.idle":"2023-07-01T19:46:03.983407Z","shell.execute_reply.started":"2023-07-01T19:46:03.973296Z","shell.execute_reply":"2023-07-01T19:46:03.982111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AggFeatureExtractor(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, group_col, agg_col, agg_func):\n        self.group_col = group_col\n        self.group_col_name = ''\n        for col in group_col:\n            self.group_col_name += col\n        self.agg_col = agg_col\n        self.agg_func = agg_func\n        self.agg_df = None\n        self.medians = None\n        \n    def fit(self, X, y=None):\n        group_col = self.group_col\n        agg_col = self.agg_col\n        agg_func = self.agg_func\n        \n        self.agg_df = X.groupby(group_col)[agg_col].agg(agg_func)\n        self.agg_df.columns = [f'{self.group_col_name}_{agg}_{_agg_col}' for _agg_col in agg_col for agg in agg_func]\n        self.medians = X[agg_col].median()\n        \n        return self\n    \n    def transform(self, X):\n        group_col = self.group_col\n        agg_col = self.agg_col\n        agg_func = self.agg_func\n        agg_df = self.agg_df\n        medians = self.medians\n        \n        X_merged = pd.merge(X, agg_df, left_on=group_col, right_index=True, how='left')\n        X_merged.fillna(medians, inplace=True)\n        X_agg = X_merged.loc[:, [f'{self.group_col_name}_{agg}_{_agg_col}' for _agg_col in agg_col for agg in agg_func]]\n        \n        return X_agg\n    \n    def fit_transform(self, X, y=None):\n        self.fit(X, y)\n        X_agg = self.transform(X)\n        return X_agg","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:04.548982Z","iopub.execute_input":"2023-07-01T19:46:04.549474Z","iopub.status.idle":"2023-07-01T19:46:04.561105Z","shell.execute_reply.started":"2023-07-01T19:46:04.549438Z","shell.execute_reply":"2023-07-01T19:46:04.559648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate train and original dataframes, and prepare train and test sets\ntrain = pd.concat([df_train, original])\ntest = df_test.copy()\n\nX_train = train.drop(columns = target_col).reset_index(drop=True)\ny_train = train.loc[:, target_col].reset_index(drop=True)\nX_test = test.reset_index(drop=True)\n\n# Create combination Features\nX_train, _ = create_features(X_train)\nX_test, _ = create_features(X_test)\n\n# Aggregate Features\ngroup_cols = [\n        ['EState_VSA2'], ['HallKierAlpha'], ['NumHeteroatoms'], \n        ['PEOE_VSA10'], ['PEOE_VSA14'], ['PEOE_VSA6'], ['PEOE_VSA7'], ['PEOE_VSA8'],\n        ['SMR_VSA10'], ['SMR_VSA5'], ['SlogP_VSA3'], ['fr_COO'], #['fr_COO2'],\n]\nagg_col = [\n    'BertzCT',\n    'Chi1', \n    'Chi1n', \n    'Chi1v', \n    'Chi2n', \n    'Chi2v', \n    'Chi3v',\n    'EState_VSA1', \n    'ExactMolWt', \n    'FpDensityMorgan1', \n    'FpDensityMorgan2', \n    'FpDensityMorgan3',\n    'HeavyAtomMolWt',  \n    'MaxAbsEStateIndex', \n    'MinEStateIndex', \n    'VSA_EState9'\n]\nagg_train, agg_test = [], []\nfor group_col in group_cols:\n    agg_extractor = AggFeatureExtractor(group_col=group_col, agg_col=agg_col, agg_func=['mean', 'std'])\n    agg_extractor.fit(pd.concat([X_train, X_test], axis=0))\n    agg_train.append(agg_extractor.transform(X_train))\n    agg_test.append(agg_extractor.transform(X_test))\nX_train = pd.concat([X_train] + agg_train, axis=1).fillna(0)\nX_test = pd.concat([X_test] + agg_test, axis=1).fillna(0)\n\n# Category Encoders\nX_train, X_test, _ = cat_encoder(X_train, X_test, cat_cols, encode='label')\n\n\n# StandardScaler\nsc = StandardScaler() # MinMaxScaler or StandardScaler\nX_train[numerical_columns] = sc.fit_transform(X_train[numerical_columns])\nX_test[numerical_columns] = sc.transform(X_test[numerical_columns])\n\n# Drop_col\ndrop_cols = ['id']\nX_train.drop(drop_cols, axis=1, inplace=True)\nX_test.drop(drop_cols, axis=1, inplace=True)\n\ndel train, test, df_train, df_test\n\nprint(f\"X_train shape :{X_train.shape} , y_train shape :{y_train.shape}\")\nprint(f\"X_test shape :{X_test.shape}\")\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:05.150249Z","iopub.execute_input":"2023-07-01T19:46:05.150712Z","iopub.status.idle":"2023-07-01T19:46:08.773492Z","shell.execute_reply.started":"2023-07-01T19:46:05.150677Z","shell.execute_reply":"2023-07-01T19:46:08.772026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Model Building</h1>","metadata":{}},{"cell_type":"markdown","source":"## First Method: Optuna Ensembels","metadata":{}},{"cell_type":"code","source":"y_train_copy = y_train.copy()","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:17.398856Z","iopub.execute_input":"2023-07-01T19:46:17.399345Z","iopub.status.idle":"2023-07-01T19:46:17.405347Z","shell.execute_reply.started":"2023-07-01T19:46:17.399304Z","shell.execute_reply":"2023-07-01T19:46:17.40403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Splitter:\n    def __init__(self, n_splits=5, cat_df=pd.DataFrame(), test_size=0.5):\n        self.n_splits = n_splits\n        self.cat_df = cat_df\n        self.test_size = test_size\n\n    def split_data(self, X, y, random_state_list):\n        for random_state in random_state_list:\n            kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n            for train_index, val_index in kf.split(X, y):\n                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n                yield X_train, X_val, y_train, y_val, val_index","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:14.515165Z","iopub.execute_input":"2023-07-01T19:46:14.516652Z","iopub.status.idle":"2023-07-01T19:46:14.524529Z","shell.execute_reply.started":"2023-07-01T19:46:14.516597Z","shell.execute_reply":"2023-07-01T19:46:14.523395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OptunaWeights:\n    def __init__(self, random_state, n_trials=100):\n        self.study = None\n        self.weights = None\n        self.random_state = random_state\n        self.n_trials = n_trials\n\n    def _objective(self, trial, y_true, y_preds):\n        # Define the weights for the predictions from each model\n        weights = [trial.suggest_float(f\"weight{n}\", 1e-15, 1) for n in range(len(y_preds))]\n\n        # Calculate the weighted prediction\n        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n\n        # Calculate the score for the weighted prediction\n        score = roc_auc_score(y_true, weighted_pred)\n        return score\n\n    def fit(self, y_true, y_preds):\n        optuna.logging.set_verbosity(optuna.logging.ERROR)\n        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n        pruner = optuna.pruners.HyperbandPruner()\n        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='maximize')\n        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n        self.study.optimize(objective_partial, n_trials=self.n_trials)\n        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n\n    def predict(self, y_preds):\n        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n        return weighted_pred\n\n    def fit_predict(self, y_true, y_preds):\n        self.fit(y_true, y_preds)\n        return self.predict(y_preds)\n    \n    def weights(self):\n        return self.weights","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:14.968028Z","iopub.execute_input":"2023-07-01T19:46:14.968496Z","iopub.status.idle":"2023-07-01T19:46:14.980337Z","shell.execute_reply.started":"2023-07-01T19:46:14.968462Z","shell.execute_reply":"2023-07-01T19:46:14.97874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict EC1","metadata":{}},{"cell_type":"code","source":"# Config\ny_train = y_train_copy.loc[:, 'EC1']\n\nn_splits = 10\nrandom_state = 42\nrandom_state_list =[42]\nn_estimators = 100\ndevice = 'cpu'\nearly_stopping_rounds = 100\nverbose = False","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:56.135549Z","iopub.execute_input":"2023-06-30T17:33:56.135897Z","iopub.status.idle":"2023-06-30T17:33:56.148318Z","shell.execute_reply.started":"2023-06-30T17:33:56.135869Z","shell.execute_reply":"2023-06-30T17:33:56.147164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\nscale_pos_weight","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:56.151856Z","iopub.execute_input":"2023-06-30T17:33:56.152176Z","iopub.status.idle":"2023-06-30T17:33:56.164246Z","shell.execute_reply.started":"2023-06-30T17:33:56.15215Z","shell.execute_reply":"2023-06-30T17:33:56.163075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weight_0 = 1.0\nclass_weight_1 = 1.0 / scale_pos_weight\n\nclass_weights = [class_weight_0, class_weight_1]","metadata":{"execution":{"iopub.status.busy":"2023-06-30T17:33:56.165491Z","iopub.execute_input":"2023-06-30T17:33:56.165849Z","iopub.status.idle":"2023-06-30T17:33:56.175285Z","shell.execute_reply.started":"2023-06-30T17:33:56.165821Z","shell.execute_reply":"2023-06-30T17:33:56.173909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    def __init__(self, n_estimators=100, device=\"cpu\", random_state=42):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self.get_models()\n        self.models_name = list(self.get_models().keys())\n        self.len_models = len(self.models)\n        \n    def get_models(self):\n             \n        xgb_optuna0 = {\n            'n_estimators': 500,\n            'learning_rate': 0.010014042393742822,\n            'booster': 'gbtree',\n            'lambda': 0.03131321744836397,\n            'alpha': 0.03690926667179868,\n            'subsample': 0.5415480288839364,\n            'colsample_bytree': 0.534352840297025,\n            'max_depth': 5,\n            'min_child_weight': 1,\n            'eta': 0.263110198744306,\n            'gamma': 0.2833843987379326,\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n        \n        xgb_optuna1 = {\n            'n_estimators': 1500,\n            'learning_rate': 0.08901459197907591,\n            'booster': 'gbtree',\n            'lambda': 8.550251116462702,\n            'alpha': 6.92130114930949,\n            'eta': 0.7719873740829137,\n            'grow_policy': 'lossguide',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n        \n        xgb_optuna2 = {\n            'n_estimators': 550,\n            'learning_rate': 0.014551680348136895,\n            'booster': 'gbtree',\n            'lambda': 0.028738149876528587,\n            'alpha': 0.014056635017117198,\n            'subsample': 0.538653498449084,\n            'colsample_bytree': 0.518050828371974, \n            'max_depth': 4, 'min_child_weight': 4,\n            'eta': 0.6953619445477833,\n            'gamma': 0.9036568111424781,\n            'scale_pos_weight': 60,\n            'grow_policy': 'lossguide',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n    \n        xgb1_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.0503196477566407,\n            'booster': 'gbtree',\n            'lambda': 0.00379319640405843,\n            'alpha': 0.106754104302093,\n            'subsample': 0.938028434508189,\n            'colsample_bytree': 0.212545425027345,\n            'max_depth': 9,\n            'min_child_weight': 2,\n            'eta': 1.03662446190642E-07,\n            'gamma': 0.000063826049787043,\n            'grow_policy': 'lossguide',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n        xgb2_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.00282353606391198,\n            'booster': 'gbtree',\n            'lambda': 0.399776698351379,\n            'alpha': 1.01836149061356E-07,\n            'subsample': 0.957123754766769,\n            'colsample_bytree': 0.229857555596548,\n            'max_depth': 9,\n            'min_child_weight': 4,\n            'eta': 2.10637756839133E-07,\n            'gamma': 0.00314857715085414,\n            'grow_policy': 'depthwise',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n        xgb3_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.00349356650247156,\n            'booster': 'gbtree',\n            'lambda': 0.0002963239871324443,\n            'alpha': 0.0000162103492458353,\n            'subsample': 0.822994064549709,\n            'colsample_bytree': 0.244618079894501,\n            'max_depth': 10,\n            'min_child_weight': 2,\n            'eta': 8.03406601824666E-06,\n            'gamma': 3.91180893163099E-07,\n            'grow_policy': 'depthwise',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight,\n        }\n        \n        lgb_optuna0 = {\n            'num_iterations': 200,\n            'learning_rate': 0.0177811006863138,\n            'max_depth': 4,\n            'lambda': 3.217623354163234,\n            'alpha': 8.493354544976775,\n            'subsample': 0.5718058301387113,\n            'colsample_bytree': 0.5131315279744134,\n            'min_child_weight': 5,\n            'device': self.device,\n            'random_state': self.random_state\n        }\n        \n        lgb_optuna1 = {\n            'num_iterations': 200,\n            'learning_rate': 0.024714536811915398,\n            'max_depth': 9,\n            'lambda': 9.498413255934212,\n            'alpha': 7.627590925937886,\n            'subsample': 0.9680186598781285,\n            'colsample_bytree': 0.5645599877042381,\n            'min_child_weight': 1,\n            'device': self.device,\n            'random_state': self.random_state\n        }\n        \n        lgb_optuna2 = {\n            'num_iterations': 950,\n            'learning_rate': 0.012019976156417951,\n            'max_depth': 4,\n            'lambda': 6.958643473661789,\n            'alpha': 0.0012598800466591953, \n            'subsample': 0.9344619448867001,\n            'colsample_bytree': 0.9864399750557648, \n            'min_child_weight': 1,\n            'device': self.device,\n            'random_state': self.random_state\n        }\n        \n        cat_optuna0 = {\n            'iterations': 650,\n            'learning_rate': 0.01484756439623765,\n            'depth': 6,\n            'l2_leaf_reg': 5.6061100632887,\n            'bagging_temperature': 1.4247109406038643,\n            'random_strength': 0.3339464318780084,\n            'random_state': self.random_state,\n            'verbose': False,\n            'class_weights': class_weights\n        }\n        \n        hist_params = {\n                'l2_regularization': 0.654926989031482,\n                'learning_rate': 0.0366207257406611,\n                'max_iter': self.n_estimators,\n                'max_depth': 30,\n                'max_bins': 255,\n                'min_samples_leaf': 52,\n                'max_leaf_nodes':12,\n                'early_stopping': True,\n                'n_iter_no_change': 50,\n                #'class_weight':'balanced',\n                'random_state': self.random_state\n            }\n        \n        mlp_params = {\n            'max_iter': 800,\n            'early_stopping': True,\n            'n_iter_no_change': 20,\n            'random_state': self.random_state,\n        }\n        \n        models = {\n            \"xgbo0\": xgb.XGBClassifier(**xgb_optuna0),\n            \"xgbo1\": xgb.XGBClassifier(**xgb_optuna1),\n            \"xgbo2\": xgb.XGBClassifier(**xgb_optuna2),\n            #\"xgb1\": xgb.XGBClassifier(**xgb1_params),\n            \"xgb2\": xgb.XGBClassifier(**xgb2_params),\n            \"xgb3\": xgb.XGBClassifier(**xgb3_params),\n            \"lgbo0\": lgb.LGBMClassifier(**lgb_optuna0),\n            \"lgbo1\": lgb.LGBMClassifier(**lgb_optuna1),\n            \"lgbo2\": lgb.LGBMClassifier(**lgb_optuna2),\n            \"cato0\": CatBoostClassifier(**cat_optuna0),\n            'hgb': HistGradientBoostingClassifier(**hist_params),\n            #'mlp': MLPClassifier(**mlp_params, hidden_layer_sizes=(100,)),\n            'rf': RandomForestClassifier(n_estimators=500, n_jobs=-1, class_weight=\"balanced\", random_state=self.random_state),\n            #'lr': LogisticRegressionCV(max_iter=2000, random_state=self.random_state)\n        }\n        return models","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-30T17:33:56.176704Z","iopub.execute_input":"2023-06-30T17:33:56.176998Z","iopub.status.idle":"2023-06-30T17:33:56.210474Z","shell.execute_reply.started":"2023-06-30T17:33:56.176973Z","shell.execute_reply":"2023-06-30T17:33:56.20917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data\nsplitter = Splitter(n_splits=n_splits, cat_df= y_train)\nsplits = splitter.split_data(X_train, y_train, random_state_list=random_state_list)\n\n# Initialize an array for storing test predictions\nclassifier = Classifier(n_estimators=n_estimators, device=device, random_state=random_state)\ntest_predss = np.zeros((X_test.shape[0]))\noof_predss = np.zeros((X_train.shape[0]))\nensemble_score = []\nweights = []\nmodels_name = [_ for _ in classifier.models_name if ('xgb' in _) or ('lgb' in _) or ('cat' in _)]\ntrained_models = dict(zip(models_name, [[] for _ in range(classifier.len_models)]))\nscore_dict = dict(zip(classifier.models_name, [[] for _ in range(len(classifier.models_name))]))\n\nfor i, (X_train_, X_val, y_train_, y_val, val_index) in enumerate(splits):\n    \n    n = i % n_splits\n    m = i // n_splits\n    \n\n    # Classifier models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n\n    # Store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n\n    # Loop over each base model and fit it\n    for name, model in models.items():\n        if ('xgb' in name) or ('lgb' in name):\n            model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n            \n        elif 'cat' in name :\n                model.fit(\n                    Pool(X_train_, y_train_, cat_features=cat_cols), eval_set=Pool(X_val, y_val, cat_features=cat_cols),\n                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n        else:\n            model.fit(X_train_, y_train_)\n            \n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n\n        test_pred = model.predict_proba(X_test)[:, 1]\n        y_val_pred = model.predict_proba(X_val)[:, 1]\n\n        score = roc_auc_score(y_val, y_val_pred)\n        score_dict[name].append(score)\n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] ROC-AUC score: {score:.5f}')\n\n        oof_preds.append(y_val_pred)\n        test_preds.append(test_pred)\n\n    # Use OptunaWeights\n    optweights = OptunaWeights(random_state)\n    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n\n    score = roc_auc_score(y_val, y_val_pred)\n    print(f'Ensemble [FOLD-{n} SEED-{random_state_list[m]}] ROC-AUC score {score:.5f} \\n')\n    ensemble_score.append(score)\n    weights.append(optweights.weights)\n\n    # Predict to X_test by the best ensemble weights\n    test_predss += optweights.predict(test_preds) / (n_splits * len(random_state_list))\n    oof_predss[X_val.index] = optweights.predict(oof_preds)\n\n    gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-30T17:33:56.217214Z","iopub.execute_input":"2023-06-30T17:33:56.217557Z","iopub.status.idle":"2023-06-30T19:11:15.900107Z","shell.execute_reply.started":"2023-06-30T17:33:56.217529Z","shell.execute_reply":"2023-06-30T19:11:15.89906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean score of the ensemble\nmean_score = np.mean(ensemble_score)\nstd_score = np.std(ensemble_score)\nprint(f'Mean Optuna Ensemble {mean_score:.5f} ± {std_score:.5f} \\n')\n\nprint('--- Optuna Weights---')\nmean_weights = np.mean(weights, axis=0)\nstd_weights = np.std(weights, axis=0)\nfor name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:11:15.901702Z","iopub.execute_input":"2023-06-30T19:11:15.902358Z","iopub.status.idle":"2023-06-30T19:11:15.912393Z","shell.execute_reply.started":"2023-06-30T19:11:15.902318Z","shell.execute_reply":"2023-06-30T19:11:15.911171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec1_test_predss = test_predss","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:11:15.914035Z","iopub.execute_input":"2023-06-30T19:11:15.91443Z","iopub.status.idle":"2023-06-30T19:11:15.927093Z","shell.execute_reply.started":"2023-06-30T19:11:15.914394Z","shell.execute_reply":"2023-06-30T19:11:15.925616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/tetsutani/ps3e18-eda-ensemble-ml-pipeline-binarypredictict#Make-Submission\n\nmy_palette = sns.cubehelix_palette(n_colors = 7, start=.46, rot=-.45, dark = .2, hue=0.95, as_cmap=True)\n\ndef show_confusion_roc(oof, title='Model Evaluation Results'):\n    f, ax = plt.subplots(1, 2, figsize=(16, 6))\n    df = pd.DataFrame({'preds': oof[0], 'target': oof[1]})\n    cm = confusion_matrix(df.target, df.preds.ge(0.5).astype(int))\n    cm_display = ConfusionMatrixDisplay(cm).plot(cmap=my_palette, ax=ax[0])\n    ax[0].grid(False)\n    RocCurveDisplay.from_predictions(df.target, df.preds, ax=ax[1])\n    ax[1].grid(True)\n    plt.suptitle(f'{title}', fontsize=12, fontweight='bold')\n    plt.tight_layout()\n\nshow_confusion_roc(oof=[oof_predss, y_train], title='EC1 OOF Evaluation Results')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:11:15.92844Z","iopub.execute_input":"2023-06-30T19:11:15.92915Z","iopub.status.idle":"2023-06-30T19:11:16.838101Z","shell.execute_reply.started":"2023-06-30T19:11:15.929119Z","shell.execute_reply":"2023-06-30T19:11:16.837027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_predss","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:11:16.839504Z","iopub.execute_input":"2023-06-30T19:11:16.839897Z","iopub.status.idle":"2023-06-30T19:11:16.846916Z","shell.execute_reply.started":"2023-06-30T19:11:16.839869Z","shell.execute_reply":"2023-06-30T19:11:16.845881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict EC2","metadata":{}},{"cell_type":"markdown","source":"I decided to add EC1 oof predicts as a feature to train dataset for EC2 predict","metadata":{}},{"cell_type":"code","source":"# Config\ny_train = y_train_copy.loc[:, 'EC2']\n\nn_splits = 5\nrandom_state = 2042\nrandom_state_list =[2042]\nn_estimators = 500\ndevice = 'cpu'\nearly_stopping_rounds = 300\nverbose = False","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:31.431635Z","iopub.execute_input":"2023-07-01T19:46:31.432053Z","iopub.status.idle":"2023-07-01T19:46:31.439042Z","shell.execute_reply.started":"2023-07-01T19:46:31.432024Z","shell.execute_reply":"2023-07-01T19:46:31.437647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train['EC1_pred'] = oof_predss\n# X_test['EC1_pred'] = test_predss","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:33.142066Z","iopub.execute_input":"2023-07-01T19:46:33.142503Z","iopub.status.idle":"2023-07-01T19:46:33.148072Z","shell.execute_reply.started":"2023-07-01T19:46:33.142473Z","shell.execute_reply":"2023-07-01T19:46:33.146687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\nscale_pos_weight","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:33.334515Z","iopub.execute_input":"2023-07-01T19:46:33.33494Z","iopub.status.idle":"2023-07-01T19:46:33.343786Z","shell.execute_reply.started":"2023-07-01T19:46:33.334907Z","shell.execute_reply":"2023-07-01T19:46:33.342422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weight_0 = 1.0\nclass_weight_1 = 1.0 / scale_pos_weight\n\nclass_weights = [class_weight_0, class_weight_1]","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:46:33.782676Z","iopub.execute_input":"2023-07-01T19:46:33.783135Z","iopub.status.idle":"2023-07-01T19:46:33.788401Z","shell.execute_reply.started":"2023-07-01T19:46:33.783102Z","shell.execute_reply":"2023-07-01T19:46:33.787128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    def __init__(self, n_estimators=100, device=\"cpu\", random_state=42):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self.get_models()\n        self.models_name = list(self.get_models().keys())\n        self.len_models = len(self.models)\n        \n    def get_models(self):\n        \n        lgb_optuna0 = {\n            'num_iterations': 700,\n            'learning_rate': 0.02360156976543837,\n            'max_depth': 3,\n            'lambda': 9.224535268287106,\n            'alpha': 5.103018845370762,\n            'subsample': 0.8672389489074398,\n            'colsample_bytree': 0.5454358875778684,\n            'min_child_weight': 1,\n            \n            'verbose': 0,\n            'random_state': self.random_state\n        }\n        \n        lgb1 = {\n            'objective': 'binary',\n            'metric': 'auc',\n            'feature_pre_filter': False,\n            'lambda_l1': 0.0,\n            'lambda_l2': 0.0,\n            'num_leaves': 11,\n            'feature_fraction': 0.7,\n            'bagging_fraction': 0.7499409223062861,\n            'bagging_freq': 4,\n            'min_child_samples': 20,\n            'num_iterations': 100,\n            'random_state': self.random_state\n        }\n        \n        xgb_optuna0 = {\n            'n_estimators': 750,\n            'learning_rate': 0.010553675405166283,\n            'booster': 'gbtree',\n            'lambda': 0.08612513132877414,\n            'alpha': 0.09126508798663525,\n            'subsample': 0.6643168242053055,\n            'colsample_bytree': 0.7098374281060121,\n            'max_depth': 3,\n            'min_child_weight': 1,\n            'eta': 0.20458543042851302,\n            'gamma': 0.15002104219322876,\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight\n        }\n        \n        xgb_optuna2 = {\n            'n_estimators': 550,\n            'learning_rate': 0.014551680348136895,\n            'booster': 'gbtree',\n            'lambda': 0.028738149876528587,\n            'alpha': 0.014056635017117198,\n            'subsample': 0.538653498449084,\n            'colsample_bytree': 0.518050828371974, \n            'max_depth': 4, 'min_child_weight': 4,\n            'eta': 0.6953619445477833,\n            'gamma': 0.9036568111424781,\n            'scale_pos_weight': 60,\n            'grow_policy': 'lossguide',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight\n        }\n    \n        xgb1_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.0503196477566407,\n            'booster': 'gbtree',\n            'lambda': 0.00379319640405843,\n            'alpha': 0.106754104302093,\n            'subsample': 0.938028434508189,\n            'colsample_bytree': 0.212545425027345,\n            'max_depth': 9,\n            'min_child_weight': 2,\n            'eta': 1.03662446190642E-07,\n            'gamma': 0.000063826049787043,\n            'grow_policy': 'lossguide',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight\n        }\n        \n        xgb2_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.00282353606391198,\n            'booster': 'gbtree',\n            'lambda': 0.399776698351379,\n            'alpha': 1.01836149061356E-07,\n            'subsample': 0.957123754766769,\n            'colsample_bytree': 0.229857555596548,\n            'max_depth': 9,\n            'min_child_weight': 4,\n            'eta': 2.10637756839133E-07,\n            'gamma': 0.00314857715085414,\n            'grow_policy': 'depthwise',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight\n        }\n        \n        xgb3_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.00349356650247156,\n            'booster': 'gbtree',\n            'lambda': 0.0002963239871324443,\n            'alpha': 0.0000162103492458353,\n            'subsample': 0.822994064549709,\n            'colsample_bytree': 0.244618079894501,\n            'max_depth': 10,\n            'min_child_weight': 2,\n            'eta': 8.03406601824666E-06,\n            'gamma': 3.91180893163099E-07,\n            'grow_policy': 'depthwise',\n            'n_jobs': -1,\n            'objective': 'binary:logistic',\n            #'eval_metric': 'auc',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'scale_pos_weight': scale_pos_weight\n        }\n        \n        xgb4_params = {\n                'n_estimators': self.n_estimators,\n                'learning_rate': 0.0258060514910791,\n                'booster': 'gbtree',\n                'lambda': 7.46721185757775E-06,\n                'alpha': 2.76013165565544E-08,\n                'subsample': 0.20132629296478,\n                'colsample_bytree': 0.45781987213833,\n                'max_depth': 5,\n                'min_child_weight': 5,\n                'eta': 3.9844926835765E-07,\n                'gamma': 0.0000620888806796158,\n                'grow_policy': 'depthwise',\n                'n_jobs': -1,\n                'objective': 'binary:logistic',\n                'eval_metric': 'auc',\n                'verbosity': 0,\n                'random_state': self.random_state,\n            }\n        xgb5_params = {\n                'n_estimators': self.n_estimators,\n                'learning_rate': 0.03045801481188,\n                'booster': 'gbtree',\n                'lambda': 0.141226751984267,\n                'alpha': 0.0000169212384166775,\n                'subsample': 0.354547691277393,\n                'colsample_bytree': 0.741230587323123,\n                'max_depth': 3,\n                'min_child_weight': 8,\n                'eta': 0.000200365560443557,\n                'gamma': 0.000793115073634548,\n                'grow_policy': 'depthwise',\n                'n_jobs': -1,\n                'objective': 'binary:logistic',\n                'eval_metric': 'auc',\n                'verbosity': 0,\n                'random_state': self.random_state,\n            }\n        \n        cat_optuna0 = {\n            'iterations': 700,\n            'learning_rate': 0.02057458403498283,\n            'depth': 5,\n            'l2_leaf_reg': 5.157899753023626,\n            'bagging_temperature': 0.8389428403768708,\n            'random_strength': 3.025644507100712,\n            'random_state': self.random_state,\n            'verbose': False,\n        }\n        \n        cat_optuna1 = {\n            'iterations': 600,\n            'learning_rate': 0.019499308200732167,\n            'depth': 8,\n            'l2_leaf_reg': 9.024309909697191,\n            'bagging_temperature': 7.9669359481998825,\n            'random_strength': 5.293875378529096,\n            'border_count': 235,\n            'auto_class_weights': 'Balanced',\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state\n        }\n        \n        cat_optuna2 = {\n            'iterations': 1000,\n            'learning_rate': 0.013171032440433215,\n            'depth': 5, \n            'l2_leaf_reg': 2.805405544410651,\n            'bagging_temperature': 5.869195302151575,\n            'random_strength': 9.103415468292203,\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state,\n            'class_weights': class_weights\n        }\n        \n        cat1_params = {\n            'iterations': self.n_estimators,\n            'depth': 3,\n            'learning_rate': 0.020258010893459,\n            'l2_leaf_reg': 0.583685138705941,\n            'random_strength': 0.177768021213223,\n            'od_type': \"Iter\", \n            'od_wait': 116,\n            'bootstrap_type': \"Bayesian\",\n            'grow_policy': 'Depthwise',\n            'bagging_temperature': 0.478048798393903,\n            'eval_metric': 'Logloss', # AUC\n            'loss_function': 'Logloss',\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state\n        }\n        \n        cat2_params = {\n            'iterations': self.n_estimators,\n            'depth': 5,\n            'learning_rate': 0.00666304601039438,\n            'l2_leaf_reg': 0.0567881687170355,\n            'random_strength': 0.00564702921370138,\n            'od_type': \"Iter\", \n            'od_wait': 93,\n            'bootstrap_type': \"Bayesian\",\n            'grow_policy': 'Depthwise',\n            'bagging_temperature': 2.48298505165348,\n            'eval_metric': 'Logloss', # AUC\n            'loss_function': 'Logloss',\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state\n        }\n        \n        cat3_params = {\n            'iterations': self.n_estimators,\n            'depth': 5,\n            'learning_rate': 0.0135730417743519,\n            'l2_leaf_reg': 0.0597353604503262,\n            'random_strength': 0.0675876600077264,\n            'od_type': \"Iter\", \n            'od_wait': 122,\n            'bootstrap_type': \"Bayesian\",\n            'grow_policy': 'Depthwise',\n            'bagging_temperature': 1.85898154006468,\n            'eval_metric': 'Logloss', # AUC\n            'loss_function': 'Logloss',\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state\n        }\n\n        cat4_params = {\n            'iterations': self.n_estimators,\n            'depth': 4,\n            'learning_rate': 0.0533074594005429,\n            'l2_leaf_reg': 4.33121673696473,\n            'random_strength': 0.00420305570017096,\n            'od_type': \"IncToDec\", \n            'od_wait': 41,\n            'bootstrap_type': \"Bayesian\",\n            'grow_policy': 'Lossguide',\n            'bagging_temperature': 9.20357081888618,\n            'eval_metric': 'AUC',\n            'loss_function': 'Logloss',\n            'task_type': self.device.upper(),\n            'verbose': False,\n            'allow_writing_files': False,\n            'random_state': self.random_state\n        }\n        \n        models = {\n            #\"lgbo0\": lgb.LGBMClassifier(**lgb_optuna0),\n            #\"xgbo1\": xgb.XGBClassifier(**xgb_optuna1),\n            \"xgbo0\": xgb.XGBClassifier(**xgb_optuna0),\n            \"xgbo2\": xgb.XGBClassifier(**xgb_optuna2),\n            \"xgb1\": xgb.XGBClassifier(**xgb1_params),\n            \"xgb2\": xgb.XGBClassifier(**xgb2_params),\n            \"xgb3\": xgb.XGBClassifier(**xgb3_params),\n            \"xgb5\": xgb.XGBClassifier(**xgb3_params),\n            \"cato0\": CatBoostClassifier(**cat_optuna0),\n            #\"cato1\": CatBoostClassifier(**cat_optuna1),\n            \"cato2\": CatBoostClassifier(**cat_optuna2),\n            #\"cat1\": CatBoostClassifier(**cat1_params),\n            #\"cat2\": CatBoostClassifier(**cat2_params),\n            #\"cat3\": CatBoostClassifier(**cat3_params),\n            \"cat4\": CatBoostClassifier(**cat4_params),\n            'rf': RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=self.random_state),\n            #'lr': LogisticRegressionCV(max_iter=2000, random_state=self.random_state)\n        }\n        return models","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-01T19:46:36.044678Z","iopub.execute_input":"2023-07-01T19:46:36.045071Z","iopub.status.idle":"2023-07-01T19:46:36.079974Z","shell.execute_reply.started":"2023-07-01T19:46:36.045044Z","shell.execute_reply":"2023-07-01T19:46:36.078486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data\nsplitter = Splitter(n_splits=n_splits, cat_df= y_train)\nsplits = splitter.split_data(X_train, y_train, random_state_list=random_state_list)\n\n# Initialize an array for storing test predictions\nclassifier = Classifier(n_estimators=n_estimators, device=device, random_state=random_state)\ntest_predss = np.zeros((X_test.shape[0]))\noof_predss = np.zeros((X_train.shape[0]))\nensemble_score = []\nweights = []\nmodels_name = [_ for _ in classifier.models_name if ('xgb' in _) or ('lgb' in _) or ('cat' in _)]\ntrained_models = dict(zip(models_name, [[] for _ in range(classifier.len_models)]))\nscore_dict = dict(zip(classifier.models_name, [[] for _ in range(len(classifier.models_name))]))\n\nfor i, (X_train_, X_val, y_train_, y_val, val_index) in enumerate(splits):\n    \n    n = i % n_splits\n    m = i // n_splits\n    \n\n    # Classifier models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n\n    # Store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n\n    # Loop over each base model and fit it\n    for name, model in models.items():\n        if ('xgb' in name) or ('lgb' in name):\n            model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n            \n        elif 'cat' in name :\n                model.fit(\n                    Pool(X_train_, y_train_, cat_features=cat_cols), eval_set=Pool(X_val, y_val, cat_features=cat_cols),\n                    early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n        else:\n            model.fit(X_train_, y_train_)\n            \n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n\n        test_pred = model.predict_proba(X_test)[:, 1]\n        y_val_pred = model.predict_proba(X_val)[:, 1]\n\n        score = roc_auc_score(y_val, y_val_pred)\n        score_dict[name].append(score)\n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] ROC-AUC score: {score:.5f}')\n\n        oof_preds.append(y_val_pred)\n        test_preds.append(test_pred)\n\n    # Use OptunaWeights\n    optweights = OptunaWeights(random_state)\n    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n\n    score = roc_auc_score(y_val, y_val_pred)\n    print(f'Ensemble [FOLD-{n} SEED-{random_state_list[m]}] ROC-AUC score {score:.5f} \\n')\n    ensemble_score.append(score)\n    weights.append(optweights.weights)\n\n    # Predict to X_test by the best ensemble weights\n    test_predss += optweights.predict(test_preds) / (n_splits * len(random_state_list))\n    oof_predss[X_val.index] = optweights.predict(oof_preds)\n\n    gc.collect()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-30T19:11:16.953359Z","iopub.execute_input":"2023-06-30T19:11:16.953919Z","iopub.status.idle":"2023-06-30T20:54:38.243012Z","shell.execute_reply.started":"2023-06-30T19:11:16.953876Z","shell.execute_reply":"2023-06-30T20:54:38.241704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean score of the ensemble\nmean_score = np.mean(ensemble_score)\nstd_score = np.std(ensemble_score)\nprint(f'Mean Optuna Ensemble {mean_score:.5f} ± {std_score:.5f} \\n')\n\nprint('--- Optuna Weights---')\nmean_weights = np.mean(weights, axis=0)\nstd_weights = np.std(weights, axis=0)\nfor name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:54:38.244713Z","iopub.execute_input":"2023-06-30T20:54:38.245159Z","iopub.status.idle":"2023-06-30T20:54:38.254157Z","shell.execute_reply.started":"2023-06-30T20:54:38.245118Z","shell.execute_reply":"2023-06-30T20:54:38.253065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec2_test_predss = test_predss","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:54:38.255805Z","iopub.execute_input":"2023-06-30T20:54:38.256235Z","iopub.status.idle":"2023-06-30T20:54:38.300921Z","shell.execute_reply.started":"2023-06-30T20:54:38.256196Z","shell.execute_reply":"2023-06-30T20:54:38.299666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_confusion_roc(oof, title='Model Evaluation Results'):\n    f, ax = plt.subplots(1, 2, figsize=(16, 6))\n    df = pd.DataFrame({'preds': oof[0], 'target': oof[1]})\n    cm = confusion_matrix(df.target, df.preds.ge(0.5).astype(int))\n    cm_display = ConfusionMatrixDisplay(cm).plot(cmap=my_palette, ax=ax[0])\n    ax[0].grid(False)\n    RocCurveDisplay.from_predictions(df.target, df.preds, ax=ax[1])\n    ax[1].grid(True)\n    plt.suptitle(f'{title}', fontsize=12, fontweight='bold')\n    plt.tight_layout()\n\nshow_confusion_roc(oof=[oof_predss, y_train], title='EC2 OOF Evaluation Results')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:54:38.302444Z","iopub.execute_input":"2023-06-30T20:54:38.303034Z","iopub.status.idle":"2023-06-30T20:54:39.100735Z","shell.execute_reply.started":"2023-06-30T20:54:38.302991Z","shell.execute_reply":"2023-06-30T20:54:39.099782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RF","metadata":{}},{"cell_type":"code","source":"# Initialize singe RF model \nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\n\n# Perform cross-val for ROC AUC scores\nroc_auc_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n\n# Perform cross-val for F1 scores\nf1_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1')\n\n# Perform cross-validation and calculate precision scores\nprecision_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='precision')\n\n# Perform cross-validation and calculate recall scores\nrecall_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='recall')\n\n# Print the cross-validation scores\nprint(\"ROC AUC scores:\", roc_auc_scores)\nprint(\"F1 scores:\", f1_scores)\nprint(\"Precision scores:\", precision_scores)\nprint(\"Recall scores:\", recall_scores)\n\n# Calculate the mean of the scores\nmean_roc_auc = roc_auc_scores.mean()\nmean_f1 = f1_scores.mean()\nmean_precision = precision_scores.mean()\nmean_recall = recall_scores.mean()\n\n# Print the mean scores\nprint(\"Mean ROC AUC score:\", mean_roc_auc)\nprint(\"Mean F1 score:\", mean_f1)\nprint(\"Mean Precision score:\", mean_precision)\nprint(\"Mean Recall score:\", mean_recall)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-01T19:54:20.089699Z","iopub.execute_input":"2023-07-01T19:54:20.090162Z","iopub.status.idle":"2023-07-01T20:00:37.488514Z","shell.execute_reply.started":"2023-07-01T19:54:20.090128Z","shell.execute_reply":"2023-07-01T20:00:37.487258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_predss = rf.predict_proba(X_test)\nrf_predss","metadata":{"execution":{"iopub.status.busy":"2023-07-01T20:11:17.786442Z","iopub.execute_input":"2023-07-01T20:11:17.786925Z","iopub.status.idle":"2023-07-01T20:11:18.431644Z","shell.execute_reply.started":"2023-07-01T20:11:17.786883Z","shell.execute_reply":"2023-07-01T20:11:18.430407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec2_test_predss_rf = rf_predss[:, 1]*0.5 + ec2_test_predss*0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Second Method: TabPFN","metadata":{}},{"cell_type":"markdown","source":"Here I decided to train my model only on the original data. This is the only way to use TabPFN as it can only work with datasets < 1000 rows. Since the original and synthesized data are different, and most likely LB testing data similar to synthesized data, the final result may not be very good. However, I decided to try this method anyway, at least to test how it works.","metadata":{}},{"cell_type":"code","source":"# install TabPFN\n\n!pip install /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n!mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n!cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:54:39.101933Z","iopub.execute_input":"2023-06-30T20:54:39.102245Z","iopub.status.idle":"2023-06-30T20:54:57.52792Z","shell.execute_reply.started":"2023-06-30T20:54:39.102219Z","shell.execute_reply":"2023-06-30T20:54:57.525841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.impute import SimpleImputer\nfrom catboost import Pool, CatBoostClassifier\nfrom tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:54:57.530292Z","iopub.execute_input":"2023-06-30T20:54:57.530757Z","iopub.status.idle":"2023-06-30T20:55:00.670352Z","shell.execute_reply.started":"2023-06-30T20:54:57.530719Z","shell.execute_reply":"2023-06-30T20:55:00.669182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/playground-series-s3e18/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/playground-series-s3e18/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/playground-series-s3e18/sample_submission.csv\")\noriginal_desc = pd.read_csv(\"/kaggle/input/ec-mixed-class/mixed_desc.csv\")\n\ntarget_col = ['EC1', 'EC2']\n\ncolumns_to_keep = ['CIDs', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n                   'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n                   'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n                   'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n                   'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n                   'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n                   'fr_COO', 'fr_COO2', 'EC1_EC2_EC3_EC4_EC5_EC6']\n\noriginal = original_desc.loc[:, columns_to_keep]\n\n# There is probably a better way to do this, but that is was first came to my mind\nfeature1 = []\nfeature2 = []\nfor x in original['EC1_EC2_EC3_EC4_EC5_EC6']:\n    feature1.append(int(x.split('_')[0]))\n    feature2.append(int(x.split('_')[1]))\n\noriginal['EC1'] = feature1\noriginal['EC2'] = feature2\n\noriginal.drop(columns = ['EC1_EC2_EC3_EC4_EC5_EC6', 'CIDs'], inplace=True)\noriginal['id'] = original.reset_index().index\n\ndf_train.drop(columns = ['EC3', 'EC4', 'EC5', 'EC6'], inplace=True)\n\n\nnumerical_columns = ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v',\n                   'Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n                   'FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha',\n                   'HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex',\n                   'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n                   'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9']\n\ncat_cols = ['fr_COO', 'fr_COO2']","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:00.672177Z","iopub.execute_input":"2023-06-30T20:55:00.673812Z","iopub.status.idle":"2023-06-30T20:55:00.901228Z","shell.execute_reply.started":"2023-06-30T20:55:00.673779Z","shell.execute_reply":"2023-06-30T20:55:00.900099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate train and original dataframes, and prepare train and test sets\ntrain = pd.concat([original]).sample(frac=0.985, random_state=42)\ntest = df_test.copy()\n\nX_train = train.drop(columns = target_col).reset_index(drop=True)\ny_train = train.loc[:, target_col].reset_index(drop=True)\nX_test = test.reset_index(drop=True)\n\n\n# Category Encoders\nX_train, X_test, _ = cat_encoder(X_train, X_test, cat_cols, encode='label')\n\n# Drop_col\ndrop_cols = ['id']\nX_train.drop(drop_cols, axis=1, inplace=True)\nX_test.drop(drop_cols, axis=1, inplace=True)\n\ndel train, test, df_train, df_test\n\nprint(f\"X_train shape :{X_train.shape} , y_train shape :{y_train.shape}\")\nprint(f\"X_test shape :{X_test.shape}\")\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:00.902929Z","iopub.execute_input":"2023-06-30T20:55:00.903248Z","iopub.status.idle":"2023-06-30T20:55:00.996819Z","shell.execute_reply.started":"2023-06-30T20:55:00.903222Z","shell.execute_reply":"2023-06-30T20:55:00.99567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weighted Ensemble uses XGBoost and TabPFN to create predictions\nclass WeightedEnsemble(BaseEstimator):\n    def __init__(self):\n        self.classifiers = [xgb.XGBClassifier(), TabPFNClassifier()]\n        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n    \n    def fit(self, X, y):\n        unique_classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = unique_classes\n        X = self.imputer.fit_transform(X)\n        for classifier in self.classifiers:\n            classifier.fit(X, y)\n    \n    def predict_proba(self, X):\n        X = self.imputer.transform(X)\n        probabilities = np.stack([classifier.predict_proba(X) for classifier in self.classifiers])\n        averaged_probabilities = np.mean(probabilities, axis=0)\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        # Weighted probabilities based on class imbalance\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)\n    \n# Define Model\nmodel = WeightedEnsemble()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:00.99818Z","iopub.execute_input":"2023-06-30T20:55:00.998517Z","iopub.status.idle":"2023-06-30T20:55:01.513056Z","shell.execute_reply.started":"2023-06-30T20:55:00.99848Z","shell.execute_reply":"2023-06-30T20:55:01.512023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform cross-validation and compute ROC AUC scores for EC1\ncv_scores = cross_val_score(model, X_train, y_train['EC1'], cv=5, scoring='roc_auc')\n\n# Print the mean and standard deviation of the cross-validation scores\nprint(\"Cross-Validation ROC AUC Scores:\")\nprint(cv_scores)\nprint(f\"Mean ROC AUC: {cv_scores.mean():.4f}\")\nprint(f\"Standard Deviation: {cv_scores.std():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:01.51679Z","iopub.execute_input":"2023-06-30T20:55:01.517119Z","iopub.status.idle":"2023-06-30T20:55:19.014355Z","shell.execute_reply.started":"2023-06-30T20:55:01.517091Z","shell.execute_reply":"2023-06-30T20:55:19.013214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform cross-validation and compute ROC AUC scores for EC2\ncv_scores = cross_val_score(model, X_train, y_train['EC2'], cv=5, scoring='roc_auc')\n\n# Print the mean and standard deviation of the cross-validation scores\nprint(\"Cross-Validation ROC AUC Scores:\")\nprint(cv_scores)\nprint(f\"Mean ROC AUC: {cv_scores.mean():.4f}\")\nprint(f\"Standard Deviation: {cv_scores.std():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:19.018057Z","iopub.execute_input":"2023-06-30T20:55:19.018396Z","iopub.status.idle":"2023-06-30T20:55:36.978956Z","shell.execute_reply.started":"2023-06-30T20:55:19.018366Z","shell.execute_reply":"2023-06-30T20:55:36.978167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict EC1","metadata":{}},{"cell_type":"code","source":"model = WeightedEnsemble()\nmodel.fit(np.array(X_train), np.array(y_train['EC1']))\n\nec1_proba = model.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:55:36.980237Z","iopub.execute_input":"2023-06-30T20:55:36.980735Z","iopub.status.idle":"2023-06-30T20:56:10.273512Z","shell.execute_reply.started":"2023-06-30T20:55:36.980706Z","shell.execute_reply":"2023-06-30T20:56:10.272638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict EC2","metadata":{}},{"cell_type":"code","source":"model = WeightedEnsemble()\nmodel.fit(np.array(X_train), np.array(y_train['EC2']))\n\nec2_proba = model.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:10.275038Z","iopub.execute_input":"2023-06-30T20:56:10.275715Z","iopub.status.idle":"2023-06-30T20:56:42.742493Z","shell.execute_reply.started":"2023-06-30T20:56:10.275676Z","shell.execute_reply":"2023-06-30T20:56:42.741672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style = \"font-family: Georgia;font-weight: bold; font-size: 30px; color: #1192AA; text-align:left\">Submission</h1>","metadata":{}},{"cell_type":"markdown","source":"### Submission for TabPFN","metadata":{}},{"cell_type":"code","source":"submission = sample_submission\n\nsubmission['EC1'] = ec1_proba[:, 1]\nsubmission['EC2'] = ec2_proba[:, 1]\n\nsubmission.to_csv(f'submission_tab.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:42.743763Z","iopub.execute_input":"2023-06-30T20:56:42.744275Z","iopub.status.idle":"2023-06-30T20:56:42.825346Z","shell.execute_reply.started":"2023-06-30T20:56:42.744247Z","shell.execute_reply":"2023-06-30T20:56:42.82455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC1', 'EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:42.826523Z","iopub.execute_input":"2023-06-30T20:56:42.827038Z","iopub.status.idle":"2023-06-30T20:56:44.108314Z","shell.execute_reply.started":"2023-06-30T20:56:42.82701Z","shell.execute_reply":"2023-06-30T20:56:44.10722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission for Ensembles","metadata":{}},{"cell_type":"code","source":"submission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss\nsubmission['EC2'] = ec2_test_predss\n\nsubmission.to_csv(f'submission_ens.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:44.110231Z","iopub.execute_input":"2023-06-30T20:56:44.110707Z","iopub.status.idle":"2023-06-30T20:56:44.185391Z","shell.execute_reply.started":"2023-06-30T20:56:44.110666Z","shell.execute_reply":"2023-06-30T20:56:44.184367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC1', 'EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:44.186901Z","iopub.execute_input":"2023-06-30T20:56:44.18769Z","iopub.status.idle":"2023-06-30T20:56:45.440752Z","shell.execute_reply.started":"2023-06-30T20:56:44.187652Z","shell.execute_reply":"2023-06-30T20:56:45.439668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec2_test_predss_1 = ec2_test_predss.copy()\nec2_test_predss_1[ec2_test_predss_1 > 0.75] = 1\n\n\nsubmission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss\nsubmission['EC2'] = ec2_test_predss_1\n\nsubmission.to_csv(f'submission_ens_1.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC1', 'EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec2_test_predss_2 = ec2_test_predss.copy()\nec2_test_predss_2[ec2_test_predss_2 > 0.75] = 1\nec2_test_predss_2[ec2_test_predss_2 < 0.4] = 0\nec1_test_predss_2 = ec1_test_predss.copy()\nec1_test_predss_2[ec1_test_predss_2 > 0.8] = 1\nec1_test_predss_2[ec1_test_predss_2 < 0.25] = 0\n\nsubmission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss\nsubmission['EC2'] = ec2_test_predss_2\n\nsubmission.to_csv(f'submission_ens_2.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC1', 'EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ec2_test_predss_3 = ec2_test_predss.copy()\nec2_test_predss_3[ec2_test_predss_3 > 0.7] = 1\nec1_test_predss_3 = ec1_test_predss.copy()\nec1_test_predss_3[ec1_test_predss_3 < 0.3] = 1\n\nsubmission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss_3\nsubmission['EC2'] = ec2_test_predss_3\n\nsubmission.to_csv(f'submission_ens_3.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission for Ensembles + TabPFN","metadata":{}},{"cell_type":"code","source":"submission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss*0.9 + ec1_proba[:, 1]*0.1\nsubmission['EC2'] = ec2_test_predss*0.7 + ec2_proba[:, 1]*0.3\n\nsubmission.to_csv(f'submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:45.442563Z","iopub.execute_input":"2023-06-30T20:56:45.44294Z","iopub.status.idle":"2023-06-30T20:56:45.518294Z","shell.execute_reply.started":"2023-06-30T20:56:45.442912Z","shell.execute_reply":"2023-06-30T20:56:45.517159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC1', 'EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T20:56:45.519742Z","iopub.execute_input":"2023-06-30T20:56:45.520026Z","iopub.status.idle":"2023-06-30T20:56:46.813955Z","shell.execute_reply.started":"2023-06-30T20:56:45.520001Z","shell.execute_reply":"2023-06-30T20:56:46.81293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss\nsubmission['EC2'] = rf_predss[:, 1]\n\nsubmission.to_csv(f'submission_rf_1.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-07-01T20:14:15.79681Z","iopub.execute_input":"2023-07-01T20:14:15.797155Z","iopub.status.idle":"2023-07-01T20:14:15.867159Z","shell.execute_reply.started":"2023-07-01T20:14:15.79713Z","shell.execute_reply":"2023-07-01T20:14:15.865763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{"execution":{"iopub.status.busy":"2023-07-01T20:14:30.196086Z","iopub.execute_input":"2023-07-01T20:14:30.1966Z","iopub.status.idle":"2023-07-01T20:14:30.765147Z","shell.execute_reply.started":"2023-07-01T20:14:30.196553Z","shell.execute_reply":"2023-07-01T20:14:30.763691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = sample_submission\n\nsubmission['EC1'] = ec1_test_predss\nsubmission['EC2'] = ec2_test_predss_rf\n\nsubmission.to_csv(f'submission_rf_2.csv', index=False)\nsubmission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(filepath, sub, target_col):\n\n    plt.figure(figsize=(16, 6))\n    sns.set_theme(style=\"whitegrid\")\n\n    sns.kdeplot(data=sub, x=target_col, fill=True, alpha=0.5, common_norm=False, label=f\"{target_col} Predict\")\n\n    plt.title('Predictive vs Training Distribution')\n    plt.legend()\n    plt.subplots_adjust(top=0.9)\n    plt.show()\n    \nfor target_col in ['EC2']:\n    plot_distribution('/kaggle/input/playground-series-s3e18', submission, target_col)","metadata":{},"execution_count":null,"outputs":[]}]}