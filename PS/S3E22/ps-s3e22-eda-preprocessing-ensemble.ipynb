{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zhukovoleksiy/ps-s3e22-eda-preprocessing-ensemble?scriptVersionId=143998391\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\"> Introduction</p>","metadata":{}},{"cell_type":"code","source":"# Misc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nfrom copy import deepcopy\nfrom functools import partial\nimport gc\nimport warnings\n\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Import libraries for Hypertuning\nimport optuna\n\n# Import libraries for gradient boosting\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.impute import KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T21:20:30.764806Z","iopub.execute_input":"2023-09-22T21:20:30.765221Z","iopub.status.idle":"2023-09-22T21:20:30.775562Z","shell.execute_reply.started":"2023-09-22T21:20:30.765187Z","shell.execute_reply":"2023-09-22T21:20:30.774011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seaborn\nrc = {\n    \"axes.facecolor\": \"#FAEEE9\",\n    \"figure.facecolor\": \"#FAEEE9\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\",\n    \"font.family\": \"arial\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4\n}\nsns.set(rc=rc)\n\n# Useful line of code to set the display option so we could see all the columns in pd dataframe\npd.set_option('display.max_columns', None)\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Functions\ndef print_sl():\n    print(\"=\" * 50)\n    print()\n\ndef show_na(df, column):\n    sns.countplot(x='outcome', data=df[df[column].isnull()])\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:20:30.777571Z","iopub.execute_input":"2023-09-22T21:20:30.777913Z","iopub.status.idle":"2023-09-22T21:20:30.794011Z","shell.execute_reply.started":"2023-09-22T21:20:30.777882Z","shell.execute_reply":"2023-09-22T21:20:30.793025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\"> Load Data</p>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')\n\ntrain_orig = pd.read_csv('/kaggle/input/horse-survival-dataset/horse.csv')\n\ntrain.drop('id',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)\n\nprint('Data Loaded Succesfully!')\nprint_sl()\n\nprint(f'train shape: {train.shape}')\nprint(f'are there any null values in train: {train.isnull().any().any()}\\n')\n\nprint(f'test shape: {test.shape}')\nprint(f'are there any null values in test: {test.isnull().any().any()}\\n')\n\nprint(f'train_orig shape: {train_orig.shape}')\nprint(f'are there any null values in test: {train_orig.isnull().any().any()}\\n')\n\ncategorical_cols = ['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time',\n                   'pain', 'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces',\n                   'abdomen', 'abdomo_appearance', 'surgical_lesion', 'cp_data']\n\nnum_cols = ['hospital_number', 'rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein',\n           'abdomo_protein', 'lesion_1', 'lesion_2', 'lesion_3']\n\ntarget = 'outcome'\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:20:30.795499Z","iopub.execute_input":"2023-09-22T21:20:30.796632Z","iopub.status.idle":"2023-09-22T21:20:30.870328Z","shell.execute_reply.started":"2023-09-22T21:20:30.796583Z","shell.execute_reply":"2023-09-22T21:20:30.869334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">  \n    <b>ðŸ’¡ Info:</b> The dataset contains a significant number of NA values.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">EDA</p>","metadata":{}},{"cell_type":"markdown","source":"### Target Distribution","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/kimtaehun/eda-and-baseline-with-multiple-models\ndef plot_count(df: pd.core.frame.DataFrame, col: str, title_name: str='Train') -> None:\n    # Set background color\n    \n    f, ax = plt.subplots(1, 2, figsize=(14, 7))\n    plt.subplots_adjust(wspace=0.2)\n\n    s1 = df[col].value_counts()\n    N = len(s1)\n\n    outer_sizes = s1\n    inner_sizes = s1/N\n\n    outer_colors = ['#9E3F00', '#eb5e00', '#ff781f']\n    inner_colors = ['#ff6905', '#ff8838', '#ffa66b']\n\n    ax[0].pie(\n        outer_sizes,colors=outer_colors, \n        labels=s1.index.tolist(), \n        startangle=90, frame=True, radius=1.3, \n        explode=([0.05]*(N-1) + [.3]),\n        wedgeprops={'linewidth' : 1, 'edgecolor' : 'white'}, \n        textprops={'fontsize': 12, 'weight': 'bold'}\n    )\n\n    textprops = {\n        'size': 13, \n        'weight': 'bold', \n        'color': 'white'\n    }\n\n    ax[0].pie(\n        inner_sizes, colors=inner_colors,\n        radius=1, startangle=90,\n        autopct='%1.f%%', explode=([.1]*(N-1) + [.3]),\n        pctdistance=0.8, textprops=textprops\n    )\n\n    center_circle = plt.Circle((0,0), .68, color='black', fc='white', linewidth=0)\n    ax[0].add_artist(center_circle)\n\n    x = s1\n    y = s1.index.tolist()\n    sns.barplot(\n        x=x, y=y, ax=ax[1],\n        palette='YlOrBr_r', orient='horizontal'\n    )\n\n    ax[1].spines['top'].set_visible(False)\n    ax[1].spines['right'].set_visible(False)\n    ax[1].tick_params(\n        axis='x',         \n        which='both',      \n        bottom=False,      \n        labelbottom=False\n    )\n\n    for i, v in enumerate(s1):\n        ax[1].text(v, i+0.1, str(v), color='black', fontweight='bold', fontsize=12)\n\n    plt.setp(ax[1].get_yticklabels(), fontweight=\"bold\")\n    plt.setp(ax[1].get_xticklabels(), fontweight=\"bold\")\n    ax[1].set_xlabel(col, fontweight=\"bold\", color='black')\n    ax[1].set_ylabel('count', fontweight=\"bold\", color='black')\n\n    f.suptitle(f'{title_name}', fontsize=18, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n\nplot_count(train, 'outcome', 'Target Variable(Outcome) Distribution')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-09-22T21:20:31.158815Z","iopub.execute_input":"2023-09-22T21:20:31.159825Z","iopub.status.idle":"2023-09-22T21:20:31.651648Z","shell.execute_reply.started":"2023-09-22T21:20:31.159783Z","shell.execute_reply":"2023-09-22T21:20:31.648958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(categorical_cols)*3))\n\nfor i, col in enumerate(categorical_cols):\n    \n    plt.subplot(len(categorical_cols)//2 + len(categorical_cols) % 2, 2, i+1)\n    sns.countplot(x=col, hue=\"outcome\", data=train, palette='YlOrRd')\n    plt.title(f\"{col} countplot by outcome\", fontweight = 'bold')\n    plt.ylim(0, train[col].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:20:31.653742Z","iopub.execute_input":"2023-09-22T21:20:31.654185Z","iopub.status.idle":"2023-09-22T21:20:37.238175Z","shell.execute_reply.started":"2023-09-22T21:20:31.654154Z","shell.execute_reply":"2023-09-22T21:20:37.237156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numerical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(num_cols) * 3))\n\nfor i, col in enumerate(num_cols):\n    # Plotting for outcome\n    plt.subplot(len(num_cols), 2, i+1)\n    sns.histplot(x=col, hue=\"outcome\", data=train, bins=30, kde=True, palette='YlOrRd')\n    plt.title(f\"{col} distribution for outcome\", fontweight=\"bold\")\n    plt.ylim(0, train[col].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:20:37.23968Z","iopub.execute_input":"2023-09-22T21:20:37.240822Z","iopub.status.idle":"2023-09-22T21:20:44.31875Z","shell.execute_reply.started":"2023-09-22T21:20:37.240785Z","shell.execute_reply":"2023-09-22T21:20:44.317963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter Matrix","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/yaaangzhou/playground-s3-e22-eda-modeling/notebook\ndef plot_pair(df_train,num_var,target,plotname):\n    '''\n    Funtion to make a pairplot:\n    df_train: total data\n    num_var: a list of numeric variable\n    target: target variable\n    '''\n    g = sns.pairplot(data=df_train, x_vars=num_var, y_vars=num_var, hue=target, corner=True,  palette='YlOrRd')\n    g._legend.set_bbox_to_anchor((0.8, 0.7))\n    g._legend.set_title(target)\n    g._legend.loc = 'upper left'\n    g._legend.get_title().set_fontsize(14)\n    for item in g._legend.get_texts():\n        item.set_fontsize(14)\n\n    plt.suptitle(plotname, ha='center', fontweight='bold', fontsize=25, y=0.98)\n    plt.show()\n\nplot_pair(train, num_cols, target, plotname = 'Scatter Matrix with Target')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:20:44.320009Z","iopub.execute_input":"2023-09-22T21:20:44.320551Z","iopub.status.idle":"2023-09-22T21:21:16.485404Z","shell.execute_reply.started":"2023-09-22T21:20:44.32052Z","shell.execute_reply":"2023-09-22T21:21:16.484278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"# Create a copy of the dataframe\ndf_encoded = train.copy()\n\n# Assuming these are your categorical variables, including 'outcome'\ncategorical_vars = ['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', \n                    'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis', \n                    'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', \n                    'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'surgical_lesion', \n                    'cp_data', 'outcome']\n\n# Label encode categorical columns\nlabel_encoders = {}\nfor column in categorical_vars:\n    le = LabelEncoder()\n    df_encoded[column] = le.fit_transform(train[column])\n    label_encoders[column] = le\n\ndef plot_correlation_heatmap(df: pd.core.frame.DataFrame, title_name: str = 'Train correlation') -> None:\n    excluded_columns = ['id']\n    columns_without_excluded = [col for col in df.columns if col not in excluded_columns]\n    corr = df[columns_without_excluded].corr()\n    \n    fig, axes = plt.subplots(figsize=(14, 10))\n    mask = np.zeros_like(corr)\n    mask[np.triu_indices_from(mask)] = True\n    sns.heatmap(corr, mask=mask, linewidths=.5, cmap='YlOrBr_r', annot=True, annot_kws={\"size\": 6})\n    plt.title(title_name)\n    plt.show()\n\n# Plot correlation heatmap for encoded dataframe\nplot_correlation_heatmap(df_encoded, 'Encoded Dataset Correlation')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:16.488626Z","iopub.execute_input":"2023-09-22T21:21:16.489651Z","iopub.status.idle":"2023-09-22T21:21:18.336358Z","shell.execute_reply.started":"2023-09-22T21:21:16.489607Z","shell.execute_reply":"2023-09-22T21:21:18.335139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Data Cleaning</p>","metadata":{}},{"cell_type":"code","source":"def preprocessing(df, le_cols, ohe_cols):\n    \n    le = LabelEncoder()\n    \n    for col in le_cols:\n        df[col] = le.fit_transform(df[col])\n        \n    df = pd.get_dummies(df, columns = ohe_cols)\n    \n    df[\"pain\"] = df[\"pain\"].replace('slight', 'moderate')\n    df[\"peristalsis\"] = df[\"peristalsis\"].replace('distend_small', 'normal')\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].replace('serosanguious', 'absent')\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].replace('slight', 'none')\n        \n    df[\"temp_of_extremities\"] = df[\"temp_of_extremities\"].fillna(\"normal\").map({'cold': 0, 'cool': 1, 'normal': 2, 'warm': 3})\n    df[\"peripheral_pulse\"] = df[\"peripheral_pulse\"].fillna(\"normal\").map({'absent': 0, 'reduced': 1, 'normal': 2, 'increased': 3})\n    df[\"capillary_refill_time\"] = df[\"capillary_refill_time\"].fillna(\"3\").map({'less_3_sec': 0, '3': 1, 'more_3_sec': 2})\n    df[\"pain\"] = df[\"pain\"].fillna(\"depressed\").map({'alert': 0, 'depressed': 1, 'moderate': 2, 'mild_pain': 3, 'severe_pain': 4, 'extreme_pain': 5})\n    df[\"peristalsis\"] = df[\"peristalsis\"].fillna(\"hypomotile\").map({'hypermotile': 0, 'normal': 1, 'hypomotile': 2, 'absent': 3})\n    df[\"abdominal_distention\"] = df[\"abdominal_distention\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'moderate': 2, 'severe': 3})\n    df[\"nasogastric_tube\"] = df[\"nasogastric_tube\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'significant': 2})\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].fillna(\"none\").map({'less_1_liter': 0, 'none': 1, 'more_1_liter': 2})\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].fillna(\"absent\").map({'absent': 0, 'decreased': 1, 'normal': 2, 'increased': 3})\n    df[\"abdomen\"] = df[\"abdomen\"].fillna(\"distend_small\").map({'normal': 0, 'other': 1, 'firm': 2,'distend_small': 3, 'distend_large': 4})\n    df[\"abdomo_appearance\"] = df[\"abdomo_appearance\"].fillna(\"serosanguious\").map({'clear': 0, 'cloudy': 1, 'serosanguious': 2})\n    \n    df.drop('lesion_3',axis=1,inplace=True)\n\n    return df\n\ndef features_engineering(df):\n    df['lesion_2'] = df['lesion_2'].apply(lambda x:1 if x>0 else 0)\n    data_preprocessed = df.copy()\n     \n    data_preprocessed[\"abs_rectal_temp\"] = (data_preprocessed[\"rectal_temp\"] - 37.8).abs()\n    data_preprocessed.drop(columns=[\"rectal_temp\"])\n    \n    return data_preprocessed","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:18.337648Z","iopub.execute_input":"2023-09-22T21:21:18.337961Z","iopub.status.idle":"2023-09-22T21:21:18.352426Z","shell.execute_reply.started":"2023-09-22T21:21:18.33792Z","shell.execute_reply":"2023-09-22T21:21:18.351274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_cols = [\"surgery\", \"age\", \"surgical_lesion\", \"cp_data\"]\nohe_cols = [\"mucous_membrane\"]\n\ntrain = preprocessing(train, le_cols, ohe_cols)\ntest = preprocessing(test, le_cols, ohe_cols)\ntrain_orig = preprocessing(train_orig, le_cols, ohe_cols)\n\n#train = encode(train, categorical_cols)\n#test = encode(test, categorical_cols)\n#train_orig = encode(train_orig, categorical_cols)\n\ntotal = pd.concat([train, train_orig], ignore_index=True)\ntotal.drop_duplicates(inplace=True)\n\ntotal = features_engineering(total)\ntest = features_engineering(test)\n\n\nprint(f'train shape: {train.shape}')\nprint(f'are there any null values in train: {train.isnull().any().any()}\\n')\n\nprint(f'test shape: {test.shape}')\nprint(f'are there any null values in test: {test.isnull().any().any()}\\n')\n\nprint(f'total shape: {total.shape}')\nprint(f'are there any null values in total: {total.isnull().any().any()}\\n')\n\ntotal.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:18.353796Z","iopub.execute_input":"2023-09-22T21:21:18.354147Z","iopub.status.idle":"2023-09-22T21:21:18.472039Z","shell.execute_reply.started":"2023-09-22T21:21:18.354118Z","shell.execute_reply":"2023-09-22T21:21:18.470838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols.remove('lesion_3')\nnum_cols.append('abs_rectal_temp')\n\n# Initialize the KNNImputer with the desired number of neighbors\nimputer = KNNImputer(n_neighbors=12) # 10 is good \n\n# Perform KNN imputation\ndf_train_imputed = pd.DataFrame(imputer.fit_transform(total[num_cols]), columns=num_cols)\ndf_test_imputed = pd.DataFrame(imputer.transform(test[num_cols]), columns=num_cols)\n\n# Check if there are still missing values in the train and test data sets\ndf_train_null = df_train_imputed[df_train_imputed.isnull().any(axis=1)]\ndf_test_null = df_test_imputed[df_test_imputed.isnull().any(axis=1)]\n\n# Display the rows with null values\nprint('No. of records with missing value in Train data set after Imputation : {}'.format(df_train_null.shape[0]))\nprint('No. of records with missing value in Test data set after Imputation : {}'.format(df_test_null.shape[0]))\n\nprint_sl()\n\n# Replace the imputed columns in the train data sets\ntotal_2 = total.drop(num_cols, axis=1).reset_index()\ntotal_2 = pd.concat([total_2, df_train_imputed], axis=1)\n\n# Replace the imputed columns in the test data sets\ntest_2 = test.drop(num_cols, axis=1).reset_index()\ntest_2 = pd.concat([test_2, df_test_imputed], axis=1)\n\n# Check the shape of the train and test data set \nprint('Shape of the Total data set : {}'.format(total_2.shape))\nprint('Shape of the Test data set : {}'.format(test_2.shape))\n\ntotal_2.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:18.473174Z","iopub.execute_input":"2023-09-22T21:21:18.473469Z","iopub.status.idle":"2023-09-22T21:21:18.601732Z","shell.execute_reply.started":"2023-09-22T21:21:18.473443Z","shell.execute_reply":"2023-09-22T21:21:18.600661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Model Building</p>","metadata":{}},{"cell_type":"code","source":"X_train = total_2.drop(columns=[target])\ny_train = total_2[target].map({'died':0,'euthanized':1,'lived':2})\nX_test = test_2\n\nprint(f'X_train shape: {X_train.shape}')\n\nprint(f'X_test shape: {X_test.shape}')\n\nprint(f'y_train shape: {y_train.shape}')\n\ndel train, test, total, test_2, total_2\ngc.collect();\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:18.603367Z","iopub.execute_input":"2023-09-22T21:21:18.603994Z","iopub.status.idle":"2023-09-22T21:21:19.095116Z","shell.execute_reply.started":"2023-09-22T21:21:18.603935Z","shell.execute_reply":"2023-09-22T21:21:19.093853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = np.unique(y_train)  # Get unique class labels\nclass_to_index = {clas: idx for idx, clas in enumerate(classes)}\ny_train_numeric = np.array([class_to_index[clas] for clas in y_train])\n\nclass_counts = np.bincount(y_train_numeric)\n\ntotal_samples = len(y_train_numeric)\n\nclass_weights = total_samples / (len(classes) * class_counts)\n\nclass_weights_dict = {clas: weight for clas, weight in zip(classes, class_weights)}","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:19.096801Z","iopub.execute_input":"2023-09-22T21:21:19.097284Z","iopub.status.idle":"2023-09-22T21:21:19.107051Z","shell.execute_reply.started":"2023-09-22T21:21:19.097242Z","shell.execute_reply":"2023-09-22T21:21:19.105841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Splitter:\n    def __init__(self, n_splits=5, test_size=0.2):\n        self.n_splits = n_splits\n        self.test_size = test_size\n\n    def split_data(self, X, y, random_state_list):\n        for random_state in random_state_list:\n                kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n                for train_index, val_index in kf.split(X, y):\n                    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n                    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n                    yield X_train, X_val, y_train, y_val","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:19.108245Z","iopub.execute_input":"2023-09-22T21:21:19.109157Z","iopub.status.idle":"2023-09-22T21:21:19.125374Z","shell.execute_reply.started":"2023-09-22T21:21:19.109125Z","shell.execute_reply":"2023-09-22T21:21:19.123843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    def __init__(self, n_estimators=1000, device=\"cpu\", random_state=0):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self._define_model()\n        self.models_name = list(self._define_model().keys())\n        self.len_models = len(self.models)\n        \n    def _define_model(self):\n        \n        xgb_optuna1 = {\n            'n_estimators': 500,\n            'learning_rate': 0.14825592807938784,\n            'booster': 'gbtree',\n            'lambda': 8.286104243394034,\n            'alpha': 3.218706261523848,\n            'subsample': 0.9641392997798903,\n            'colsample_bytree': 0.6489144243365093,\n            'max_depth': 4, \n            'min_child_weight': 3,\n            'eta': 1.230361841253566,\n            'gamma': 0.007588382469327802, \n            'grow_policy': 'depthwise',\n            'objective': 'multi:softmax',\n          #  'class_weight': class_weights_dict,\n            'random_state': self.random_state,\n        }\n        \n        xgb1_params = {\n            \"n_estimators\": 1000,\n            \"max_depth\": 3,\n            \"learning_rate\": 0.55, \n            \"min_child_weight\": 2,\n            \"colsample_bytree\": 0.9, \n            \"objective\": \"multi:softmax\", \n            \"eval_metric\": \"merror\",\n         #   'class_weight': class_weights_dict,\n            \"random_state\": self.random_state, \n        }\n\n        if self.device == 'gpu':\n            xgb_params['tree_method'] = 'gpu_hist'\n            xgb_params['predictor'] = 'gpu_predictor'\n        \n        lgb_optuna1 = {\n            'num_iterations': 200,\n            'learning_rate': 0.05087818591635374,\n            'max_depth': 10,\n            'alpha': 4.34921696876783,\n            'subsample': 0.512929283477029,\n            'colsample_bytree': 0.5421760951211009, \n            'min_child_weight': 4,\n            'random_state': self.random_state,\n            'objective': 'multiclass',\n            'class_weight':class_weights_dict,\n            'verbose': -1,\n        }\n        \n        lgb_params2 = {\n            'n_estimators': self.n_estimators,\n            'max_depth': 5,\n            'learning_rate': 0.05,\n            'subsample': 0.20,\n            'colsample_bytree': 0.56,\n            'reg_alpha': 0.25,\n            'reg_lambda': 5e-08,\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'device': self.device,\n            'random_state': self.random_state,\n            'class_weight':class_weights_dict,\n        }\n      \n        cat_optuna1 = {\n            'iterations': 700,          \n            'learning_rate': 0.06806932341035855,\n            'depth': 3,\n            'l2_leaf_reg': 4.246994639881441,\n            'bagging_temperature': 0.08262764367292164,\n            'random_strength': 6.922710769000274, \n            'border_count': 88,\n            'random_state': self.random_state,\n            'verbose': False,\n        }\n      \n        hist_params = {\n            'l2_regularization': 0.01,\n            'early_stopping': True,\n            'learning_rate': 0.01,\n            'max_iter': self.n_estimators,\n            'max_depth': 4,\n            'max_bins': 255,\n            'min_samples_leaf': 10,\n            'max_leaf_nodes':10,\n            'class_weight':'balanced',\n            'random_state': self.random_state\n        }\n        models = {\n            'xgb01': xgb.XGBClassifier(**xgb_optuna1),\n            'lgb01': lgb.LGBMClassifier(**lgb_optuna1),\n            #'hgb': HistGradientBoostingClassifier(**hist_params),\n            #'cat01': CatBoostClassifier(**cat_optuna1),\n            #'xgb': xgb.XGBClassifier(random_state=self.random_state),\n            'xgb1': xgb.XGBClassifier(**xgb1_params),\n            'lgb': lgb.LGBMClassifier(**lgb_params2),\n            #'cat': CatBoostClassifier(random_state=self.random_state),\n            #'rf': RandomForestClassifier(random_state=self.random_state),\n        }\n        \n        return models","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:43.539806Z","iopub.execute_input":"2023-09-22T21:21:43.540199Z","iopub.status.idle":"2023-09-22T21:21:43.555537Z","shell.execute_reply.started":"2023-09-22T21:21:43.540169Z","shell.execute_reply":"2023-09-22T21:21:43.554451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OptunaWeights:\n    def __init__(self, random_state, n_trials=1000):\n        self.study = None\n        self.weights = None\n        self.random_state = random_state\n        self.n_trials = n_trials\n\n    def _objective(self, trial, y_true, y_preds):\n        # Define the weights for the predictions from each model\n        weights = [trial.suggest_float(f\"weight{n}\", 1e-12, 2) for n in range(len(y_preds))]\n\n        # Calculate the weighted prediction\n        weighted_pred = np.average(np.array(y_preds), axis=0, weights=weights)\n        \n        weighted_pred_labels = np.argmax(weighted_pred, axis=1)\n        f1_micro_score = f1_score(y_true, weighted_pred_labels, average='micro')\n        return f1_micro_score\n\n    def fit(self, y_true, y_preds):\n        optuna.logging.set_verbosity(optuna.logging.ERROR)\n        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n        pruner = optuna.pruners.HyperbandPruner()\n        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='maximize')\n        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n        self.study.optimize(objective_partial, n_trials=self.n_trials)\n        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n\n    def predict(self, y_preds):\n        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n        weighted_pred = np.average(np.array(y_preds), axis=0, weights=self.weights)\n        return weighted_pred\n\n    def fit_predict(self, y_true, y_preds):\n        self.fit(y_true, y_preds)\n        return self.predict(y_preds)\n    \n    def weights(self):\n        return self.weights","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:45.104434Z","iopub.execute_input":"2023-09-22T21:21:45.105348Z","iopub.status.idle":"2023-09-22T21:21:45.115903Z","shell.execute_reply.started":"2023-09-22T21:21:45.105312Z","shell.execute_reply":"2023-09-22T21:21:45.114855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\nrandom_state = 42\nrandom_state_list = [42] \nn_estimators = 999 \nearly_stopping_rounds = 363\nverbose = False\ndevice = 'cpu'\nsplitter = Splitter(n_splits=n_splits)\n\n# Initialize an array for storing test predictions\ntest_predss = np.zeros((X_test.shape[0], 3))\nensemble_f1_score = []\nweights = []\ntrained_models = {'xgb':[], 'lgb':[], 'cat':[]}\n    \nfor i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(X_train, y_train, random_state_list=random_state_list)):\n    n = i % n_splits\n    m = i // n_splits\n            \n    # Get a set of Regressor models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n    \n    # Initialize lists to store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n    \n    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n    for name, model in models.items():\n        if ('xgb' in name) or ('lgb' in name) or ('cat' in name)  :\n            model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n        else:\n            model.fit(X_train_, y_train_)\n            \n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n        \n        test_pred = model.predict_proba(X_test)\n        y_val_pred = model.predict_proba(X_val)\n\n        y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n        f1_micro_score = f1_score(y_val, y_val_pred_labels, average='micro')\n        \n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] F1 Micro Score: {f1_micro_score:.5f}')\n        \n        oof_preds.append(y_val_pred)\n        test_preds.append(test_pred)\n    \n    # Use Optuna to find the best ensemble weights\n    optweights = OptunaWeights(random_state=random_state)\n    y_val_pred = optweights.fit_predict(y_val, oof_preds)\n    \n    score = log_loss(y_val, y_val_pred)\n    y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n    f1_micro_score = f1_score(y_val, y_val_pred_labels, average='micro')\n    \n    print(f'Ensemble [FOLD-{n} SEED-{random_state_list[m]}] ---------------> F1 Micro Score: {f1_micro_score:.5f}')\n    print_sl()\n    \n    ensemble_f1_score.append(f1_micro_score)\n    weights.append(optweights.weights)\n    \n    # Predict to X_test by the best ensemble weights\n    _test_preds = optweights.predict(test_preds)\n    test_predss += _test_preds / (n_splits * len(random_state_list))\n    \n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:21:46.235774Z","iopub.execute_input":"2023-09-22T21:21:46.237012Z","iopub.status.idle":"2023-09-22T21:22:51.342671Z","shell.execute_reply.started":"2023-09-22T21:21:46.236967Z","shell.execute_reply":"2023-09-22T21:22:51.341597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean LogLoss score of the ensemble\nmean_score = np.mean(ensemble_f1_score)\nstd_score = np.std(ensemble_f1_score)\nprint(f'Ensemble F1 score {mean_score:.5f} Â± {std_score:.5f}')\n\n# Print the mean and standard deviation of the ensemble weights for each model\nprint('--- Model Weights ---')\nmean_weights = np.mean(weights, axis=0)\nstd_weights = np.std(weights, axis=0)\nfor name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n    print(f'{name}: {mean_weight:.5f} Â± {std_weight:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:23:00.607274Z","iopub.execute_input":"2023-09-22T21:23:00.607634Z","iopub.status.idle":"2023-09-22T21:23:00.61583Z","shell.execute_reply.started":"2023-09-22T21:23:00.607605Z","shell.execute_reply":"2023-09-22T21:23:00.614137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Predict and Submit</p>","metadata":{}},{"cell_type":"code","source":"# Post processing:\nfor pred in test_predss:\n    if (pred[1] < pred[2]) and ((pred[2] + pred[1]) > pred[0]): \n        pred[0] = 0\n        pred[1] = 0\n        pred[2] = 1\n        \n    if (pred[0] > pred[2]) and (pred[0] > pred[1]) and (pred[0] - pred[1] < 0.3): \n        pred[0] = 0\n        pred[1] = 1\n        pred[2] = 0","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:43:30.64143Z","iopub.execute_input":"2023-09-22T21:43:30.6418Z","iopub.status.idle":"2023-09-22T21:43:30.650223Z","shell.execute_reply.started":"2023-09-22T21:43:30.64177Z","shell.execute_reply":"2023-09-22T21:43:30.649031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': np.argmax(test_predss, axis=1)})\nsubmission['outcome'] = submission['outcome'].map({0:'died',1:'euthanized',2:'lived'})\nsubmission.to_csv('submission.csv',index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:43:31.158134Z","iopub.execute_input":"2023-09-22T21:43:31.158503Z","iopub.status.idle":"2023-09-22T21:43:31.175256Z","shell.execute_reply.started":"2023-09-22T21:43:31.158475Z","shell.execute_reply":"2023-09-22T21:43:31.174315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_count(submission, 'outcome', 'Predicted Variable(Outcome) Distribution')","metadata":{"execution":{"iopub.status.busy":"2023-09-22T21:43:31.9374Z","iopub.execute_input":"2023-09-22T21:43:31.937748Z","iopub.status.idle":"2023-09-22T21:43:32.396076Z","shell.execute_reply.started":"2023-09-22T21:43:31.937719Z","shell.execute_reply":"2023-09-22T21:43:32.395102Z"},"trusted":true},"execution_count":null,"outputs":[]}]}